<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh-Hans" xml:lang="zh-Hans"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="李世纪">

<title>16 广义矩估计法 – 计量模型及应用</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/17蒙特卡洛法与自助法.html" rel="next">
<link href="../chapters/15最大似然估计法.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-70a47bd5681a7291082a5b9f83d58762.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交",
    "search-label": "搜索"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="science-textbook.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/14大样本理论.html">III 理论与算法</a></li><li class="breadcrumb-item"><a href="../chapters/16广义矩估计法.html"><span class="chapter-title">16 广义矩估计法</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="展开或折叠侧边栏导航" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="搜索" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">计量模型及应用</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="搜索"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">简介</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">说明</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">I 数据与模型</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/1线性回归.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">1 线性回归基础</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/2横截面数据分析.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">2 横截面数据：假设违反的诊断与修正</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/3面板数据模型.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">3 面板数据模型</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/4时间序列分析.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">4 时间序列分析</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/5离散与受限因变量模型.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">5 离散数据与受限因变量模型</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">II 因果推断方法</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/6因果推断框架.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">6 因果推断框架</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/7工具变量法.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">7 工具变量法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/8倾向得分匹配.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">8 倾向得分匹配</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/9双重差分法.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">9 双重差分法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10断点回归.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">10 断点回归</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11合成控制法.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">11 合成控制法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12回归控制法.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">12 回归控制法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13中介效应与调节效应.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">13 中介效应与调节效应</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">III 理论与算法</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="展开或折叠此栏">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/14大样本理论.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">14 大样本理论</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/15最大似然估计法.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">15 最大似然估计理论</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/16广义矩估计法.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">16 广义矩估计法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/17蒙特卡洛法与自助法.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">17 蒙特卡洛法与自助法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/18优化算法与数值方法.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">18 数值优化与矩阵方法</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/19机器学习在计量中的应用.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">19 机器学习在计量中的应用</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">目录</h2>
   
  <ul>
  <li><a href="#本章导读" id="toc-本章导读" class="nav-link active" data-scroll-target="#本章导读">本章导读</a></li>
  <li><a href="#回顾传统估计方法的矩条件视角" id="toc-回顾传统估计方法的矩条件视角" class="nav-link" data-scroll-target="#回顾传统估计方法的矩条件视角">15.1 回顾：传统估计方法的矩条件视角</a>
  <ul class="collapse">
  <li><a href="#ols的最小二乘条件正交性的矩表达" id="toc-ols的最小二乘条件正交性的矩表达" class="nav-link" data-scroll-target="#ols的最小二乘条件正交性的矩表达">OLS的最小二乘条件：正交性的矩表达</a></li>
  <li><a href="#sls的工具变量条件外生性的矩约束" id="toc-sls的工具变量条件外生性的矩约束" class="nav-link" data-scroll-target="#sls的工具变量条件外生性的矩约束">2SLS的工具变量条件：外生性的矩约束</a></li>
  <li><a href="#mle的score函数条件似然框架的矩表述" id="toc-mle的score函数条件似然框架的矩表述" class="nav-link" data-scroll-target="#mle的score函数条件似然框架的矩表述">MLE的score函数条件：似然框架的矩表述</a></li>
  <li><a href="#三种方法的矩条件统一表述" id="toc-三种方法的矩条件统一表述" class="nav-link" data-scroll-target="#三种方法的矩条件统一表述">三种方法的矩条件统一表述</a></li>
  </ul></li>
  <li><a href="#广义矩方法的基本框架" id="toc-广义矩方法的基本框架" class="nav-link" data-scroll-target="#广义矩方法的基本框架">15.2 广义矩方法的基本框架</a>
  <ul class="collapse">
  <li><a href="#矩条件的一般形式从特殊到一般的升华" id="toc-矩条件的一般形式从特殊到一般的升华" class="nav-link" data-scroll-target="#矩条件的一般形式从特殊到一般的升华">矩条件的一般形式：从特殊到一般的升华</a></li>
  <li><a href="#gmm估计量的定义统一框架的构建" id="toc-gmm估计量的定义统一框架的构建" class="nav-link" data-scroll-target="#gmm估计量的定义统一框架的构建">GMM估计量的定义：统一框架的构建</a></li>
  <li><a href="#识别条件估计一致性的基石" id="toc-识别条件估计一致性的基石" class="nav-link" data-scroll-target="#识别条件估计一致性的基石">识别条件：估计一致性的基石</a></li>
  <li><a href="#统一框架下的传统方法再阐释" id="toc-统一框架下的传统方法再阐释" class="nav-link" data-scroll-target="#统一框架下的传统方法再阐释">统一框架下的传统方法再阐释</a></li>
  </ul></li>
  <li><a href="#gmm的统计性质" id="toc-gmm的统计性质" class="nav-link" data-scroll-target="#gmm的统计性质">15.3 GMM的统计性质</a>
  <ul class="collapse">
  <li><a href="#一致性大样本下的确定性" id="toc-一致性大样本下的确定性" class="nav-link" data-scroll-target="#一致性大样本下的确定性">一致性：大样本下的确定性</a></li>
  <li><a href="#渐近正态性分布形态的刻画" id="toc-渐近正态性分布形态的刻画" class="nav-link" data-scroll-target="#渐近正态性分布形态的刻画">渐近正态性：分布形态的刻画</a></li>
  <li><a href="#效率与最优gmm方差最小化的追求" id="toc-效率与最优gmm方差最小化的追求" class="nav-link" data-scroll-target="#效率与最优gmm方差最小化的追求">效率与最优GMM：方差最小化的追求</a></li>
  <li><a href="#假设检验模型设定的评估" id="toc-假设检验模型设定的评估" class="nav-link" data-scroll-target="#假设检验模型设定的评估">假设检验：模型设定的评估</a></li>
  <li><a href="#统一视角下的传统方法性质" id="toc-统一视角下的传统方法性质" class="nav-link" data-scroll-target="#统一视角下的传统方法性质">统一视角下的传统方法性质</a></li>
  </ul></li>
  <li><a href="#gmm的具体应用" id="toc-gmm的具体应用" class="nav-link" data-scroll-target="#gmm的具体应用">15.4 GMM的具体应用</a>
  <ul class="collapse">
  <li><a href="#线性模型的gmm估计从传统到一般" id="toc-线性模型的gmm估计从传统到一般" class="nav-link" data-scroll-target="#线性模型的gmm估计从传统到一般">线性模型的GMM估计：从传统到一般</a></li>
  <li><a href="#非线性模型的gmm估计超越线性框架" id="toc-非线性模型的gmm估计超越线性框架" class="nav-link" data-scroll-target="#非线性模型的gmm估计超越线性框架">非线性模型的GMM估计：超越线性框架</a></li>
  <li><a href="#时间序列gmm序列相关的处理" id="toc-时间序列gmm序列相关的处理" class="nav-link" data-scroll-target="#时间序列gmm序列相关的处理">时间序列GMM：序列相关的处理</a></li>
  <li><a href="#应用实例解析" id="toc-应用实例解析" class="nav-link" data-scroll-target="#应用实例解析">应用实例解析</a></li>
  </ul></li>
  <li><a href="#实践中的gmm问题与对策" id="toc-实践中的gmm问题与对策" class="nav-link" data-scroll-target="#实践中的gmm问题与对策">15.5 实践中的GMM：问题与对策</a>
  <ul class="collapse">
  <li><a href="#弱工具变量问题识别不足的挑战" id="toc-弱工具变量问题识别不足的挑战" class="nav-link" data-scroll-target="#弱工具变量问题识别不足的挑战">弱工具变量问题：识别不足的挑战</a></li>
  <li><a href="#权重矩阵估计效率与稳定的平衡" id="toc-权重矩阵估计效率与稳定的平衡" class="nav-link" data-scroll-target="#权重矩阵估计效率与稳定的平衡">权重矩阵估计：效率与稳定的平衡</a></li>
  <li><a href="#矩条件选择数量与质量的权衡" id="toc-矩条件选择数量与质量的权衡" class="nav-link" data-scroll-target="#矩条件选择数量与质量的权衡">矩条件选择：数量与质量的权衡</a></li>
  <li><a href="#数值优化问题" id="toc-数值优化问题" class="nav-link" data-scroll-target="#数值优化问题">数值优化问题</a></li>
  <li><a href="#软件实践建议" id="toc-软件实践建议" class="nav-link" data-scroll-target="#软件实践建议">软件实践建议</a></li>
  </ul></li>
  <li><a href="#gmm的扩展与前沿" id="toc-gmm的扩展与前沿" class="nav-link" data-scroll-target="#gmm的扩展与前沿">15.6 GMM的扩展与前沿</a>
  <ul class="collapse">
  <li><a href="#经验似然方法非参数似然的视角" id="toc-经验似然方法非参数似然的视角" class="nav-link" data-scroll-target="#经验似然方法非参数似然的视角">经验似然方法：非参数似然的视角</a></li>
  <li><a href="#局部识别与弱识别渐近理论的扩展" id="toc-局部识别与弱识别渐近理论的扩展" class="nav-link" data-scroll-target="#局部识别与弱识别渐近理论的扩展">局部识别与弱识别：渐近理论的扩展</a></li>
  <li><a href="#高维gmm大q时代的挑战" id="toc-高维gmm大q时代的挑战" class="nav-link" data-scroll-target="#高维gmm大q时代的挑战">高维GMM：大<span class="math inline">\(q\)</span>时代的挑战</a></li>
  <li><a href="#机器学习与gmm的结合" id="toc-机器学习与gmm的结合" class="nav-link" data-scroll-target="#机器学习与gmm的结合">机器学习与GMM的结合</a></li>
  <li><a href="#计算前沿高效算法与软件" id="toc-计算前沿高效算法与软件" class="nav-link" data-scroll-target="#计算前沿高效算法与软件">计算前沿：高效算法与软件</a></li>
  </ul></li>
  <li><a href="#本章总结" id="toc-本章总结" class="nav-link" data-scroll-target="#本章总结">本章总结</a>
  <ul class="collapse">
  <li><a href="#一统一性认知" id="toc-一统一性认知" class="nav-link" data-scroll-target="#一统一性认知">一、统一性认知</a></li>
  <li><a href="#二实践性智慧" id="toc-二实践性智慧" class="nav-link" data-scroll-target="#二实践性智慧">二、实践性智慧</a></li>
  <li><a href="#三前沿性视野" id="toc-三前沿性视野" class="nav-link" data-scroll-target="#三前沿性视野">三、前沿性视野</a></li>
  <li><a href="#四批判性思考" id="toc-四批判性思考" class="nav-link" data-scroll-target="#四批判性思考">四、批判性思考</a></li>
  <li><a href="#五学习建议" id="toc-五学习建议" class="nav-link" data-scroll-target="#五学习建议">五、学习建议</a></li>
  </ul></li>
  <li><a href="#进一步阅读" id="toc-进一步阅读" class="nav-link" data-scroll-target="#进一步阅读">进一步阅读</a>
  <ul class="collapse">
  <li><a href="#经典文献" id="toc-经典文献" class="nav-link" data-scroll-target="#经典文献">经典文献</a></li>
  <li><a href="#前沿研究" id="toc-前沿研究" class="nav-link" data-scroll-target="#前沿研究">前沿研究</a></li>
  <li><a href="#软件资源" id="toc-软件资源" class="nav-link" data-scroll-target="#软件资源">软件资源</a></li>
  <li><a href="#在线课程" id="toc-在线课程" class="nav-link" data-scroll-target="#在线课程">在线课程</a></li>
  </ul></li>
  <li><a href="#思考与练习" id="toc-思考与练习" class="nav-link" data-scroll-target="#思考与练习">思考与练习</a>
  <ul class="collapse">
  <li><a href="#理论推导" id="toc-理论推导" class="nav-link" data-scroll-target="#理论推导">理论推导</a></li>
  <li><a href="#实证分析" id="toc-实证分析" class="nav-link" data-scroll-target="#实证分析">实证分析</a></li>
  <li><a href="#研究设计" id="toc-研究设计" class="nav-link" data-scroll-target="#研究设计">研究设计</a></li>
  <li><a href="#批判性思考" id="toc-批判性思考" class="nav-link" data-scroll-target="#批判性思考">批判性思考</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/14大样本理论.html">III 理论与算法</a></li><li class="breadcrumb-item"><a href="../chapters/16广义矩估计法.html"><span class="chapter-title">16 广义矩估计法</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">16 广义矩估计法</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">作者</div>
    <div class="quarto-title-meta-contents">
             <p>李世纪 </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="本章导读" class="level2">
<h2 class="anchored" data-anchor-id="本章导读">本章导读</h2>
<p>计量经济学的演进如同一棵知识之树，从最初的最小二乘法这一主干，逐渐生长出处理内生性的工具变量法、基于分布假设的最大似然法等多个分支。然而，这些看似迥异的方法背后，隐藏着深刻的统一性逻辑。1982年，拉尔斯·彼得·汉森提出的广义矩方法（GMM）正是揭示这一统一性的关键框架，它将各种估计方法置于共同的矩条件基础之上。</p>
<p>广义矩方法的精妙之处在于其哲学思辨：任何参数估计问题本质上都是寻找使样本矩条件接近总体矩条件的参数值。这一思想不仅统一了传统方法，更为处理复杂的经济计量问题——从资产定价到动态面板，从宏观时间序列到微观因果推断——提供了灵活而强大的工具。</p>
<p>本章将引领您完成一次从具体到抽象、再从抽象回到具体的思维旅程。我们将首先以全新视角重新审视OLS、2SLS和MLE，揭示它们共有的矩条件本质；然后系统构建GMM的一般理论框架；接着探讨其在各类模型中的应用与实践挑战；最后展望前沿发展。通过本章学习，您将掌握：</p>
<ol type="1">
<li>将传统估计方法统一表述为GMM特例的能力</li>
<li>GMM估计的完整实施流程与统计推断方法</li>
<li>在实际研究中恰当运用GMM解决内生性、动态性等问题的技能</li>
<li>对估计方法演进逻辑的深刻理解</li>
</ol>
<p>让我们开始这次统一性探索之旅。</p>
<hr>
</section>
<section id="回顾传统估计方法的矩条件视角" class="level2">
<h2 class="anchored" data-anchor-id="回顾传统估计方法的矩条件视角">15.1 回顾：传统估计方法的矩条件视角</h2>
<section id="ols的最小二乘条件正交性的矩表达" class="level3">
<h3 class="anchored" data-anchor-id="ols的最小二乘条件正交性的矩表达">OLS的最小二乘条件：正交性的矩表达</h3>
<p>考虑经典线性回归模型： <span class="math display">\[
y_i = \mathbf{x}_i'\pmb{\beta} + \varepsilon_i, \quad i=1,\ldots,n
\]</span></p>
<p>OLS估计量 <span class="math inline">\(\hat{\pmb{\beta}}_{OLS}\)</span> 通过最小化残差平方和获得，其一阶条件为： <span class="math display">\[
\sum_{i=1}^n \mathbf{x}_i(y_i - \mathbf{x}_i'\pmb{\beta}) = 0
\]</span></p>
<p>这一条件可重述为<strong>样本矩条件</strong>： <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n \mathbf{x}_i(y_i - \mathbf{x}_i'\pmb{\beta}) = 0
\]</span></p>
<p>对应的<strong>总体矩条件</strong>为： <span class="math display">\[
E[\mathbf{x}_i\varepsilon_i] = E[\mathbf{x}_i(y_i - \mathbf{x}_i'\pmb{\beta}_0)] = 0
\]</span></p>
<p><strong>关键洞见</strong>：OLS本质上是求解<span class="math inline">\(k\)</span>个矩条件的系统，每个条件对应一个解释变量与误差项的正交性要求。当<span class="math inline">\(E[\mathbf{x}_i\varepsilon_i]=0\)</span>成立时，我们获得了参数的一致估计。</p>
</section>
<section id="sls的工具变量条件外生性的矩约束" class="level3">
<h3 class="anchored" data-anchor-id="sls的工具变量条件外生性的矩约束">2SLS的工具变量条件：外生性的矩约束</h3>
<p>当解释变量存在内生性时，工具变量法应运而生。设内生模型： <span class="math display">\[
y_i = \mathbf{x}_i'\pmb{\beta} + \varepsilon_i, \quad E[\mathbf{x}_i\varepsilon_i] \neq 0
\]</span></p>
<p>引入工具变量<span class="math inline">\(\mathbf{z}_i\)</span>满足： 1. 相关性：<span class="math inline">\(Cov(\mathbf{z}_i, \mathbf{x}_i) \neq 0\)</span> 2. 外生性：<span class="math inline">\(Cov(\mathbf{z}_i, \varepsilon_i) = 0\)</span></p>
<p>外生性条件可表述为矩条件： <span class="math display">\[
E[\mathbf{z}_i\varepsilon_i] = E[\mathbf{z}_i(y_i - \mathbf{x}_i'\pmb{\beta}_0)] = 0
\]</span></p>
<p>设<span class="math inline">\(\dim(\mathbf{z}_i) = L \geq k = \dim(\pmb{\beta})\)</span>，则我们有<span class="math inline">\(L\)</span>个矩条件。当<span class="math inline">\(L = k\)</span>时，系统恰好识别；当<span class="math inline">\(L &gt; k\)</span>时，系统过度识别，需要特殊处理来平衡这<span class="math inline">\(L\)</span>个条件。</p>
<p><strong>统一性洞察</strong>：2SLS可视为特定权重矩阵下的GMM估计量。定义矩条件函数<span class="math inline">\(g(\mathbf{w}_i, \pmb{\beta}) = \mathbf{z}_i(y_i - \mathbf{x}_i'\pmb{\beta})\)</span>，选择权重矩阵<span class="math inline">\(\mathbf{W}_n = (\frac{1}{n}\sum \mathbf{z}_i\mathbf{z}_i')^{-1}\)</span>，则GMM解即为2SLS估计量。</p>
</section>
<section id="mle的score函数条件似然框架的矩表述" class="level3">
<h3 class="anchored" data-anchor-id="mle的score函数条件似然框架的矩表述">MLE的score函数条件：似然框架的矩表述</h3>
<p>设观测数据<span class="math inline">\(\mathbf{w}_i\)</span>来自参数分布<span class="math inline">\(f(\mathbf{w}_i; \pmb{\theta})\)</span>。最大似然估计最大化对数似然函数： <span class="math display">\[
\ell_n(\pmb{\theta}) = \sum_{i=1}^n \ln f(\mathbf{w}_i; \pmb{\theta})
\]</span></p>
<p>一阶条件（score函数）为： <span class="math display">\[
\frac{\partial \ell_n(\pmb{\theta})}{\partial \pmb{\theta}} = \sum_{i=1}^n \frac{\partial \ln f(\mathbf{w}_i; \pmb{\theta})}{\partial \pmb{\theta}} = 0
\]</span></p>
<p>这等价于样本矩条件： <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n s(\mathbf{w}_i; \pmb{\theta}) = 0, \quad s(\mathbf{w}_i; \pmb{\theta}) = \frac{\partial \ln f(\mathbf{w}_i; \pmb{\theta})}{\partial \pmb{\theta}}
\]</span></p>
<p>对应的总体矩条件为： <span class="math display">\[
E[s(\mathbf{w}_i; \pmb{\theta}_0)] = 0
\]</span></p>
<p>这一条件在模型设定正确时必然成立，因为score函数的期望为零。</p>
<p><strong>深刻联系</strong>：MLE可视为使用score函数作为矩条件、并以信息矩阵的逆作为最优权重矩阵的GMM。当矩条件来自score函数且使用最优权重时，GMM达到与MLE相同的渐近效率。</p>
</section>
<section id="三种方法的矩条件统一表述" class="level3">
<h3 class="anchored" data-anchor-id="三种方法的矩条件统一表述">三种方法的矩条件统一表述</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>方法</th>
<th>矩条件函数 <span class="math inline">\(g(\mathbf{w}_i, \pmb{\theta})\)</span></th>
<th>矩条件数 <span class="math inline">\(q\)</span></th>
<th>参数数 <span class="math inline">\(p\)</span></th>
<th>识别状态</th>
<th>关键假设</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>OLS</strong></td>
<td><span class="math inline">\(\mathbf{x}_i(y_i - \mathbf{x}_i'\pmb{\beta})\)</span></td>
<td><span class="math inline">\(k\)</span></td>
<td><span class="math inline">\(k\)</span></td>
<td>恰好识别</td>
<td><span class="math inline">\(E[\mathbf{x}_i\varepsilon_i]=0\)</span></td>
</tr>
<tr class="even">
<td><strong>2SLS</strong></td>
<td><span class="math inline">\(\mathbf{z}_i(y_i - \mathbf{x}_i'\pmb{\beta})\)</span></td>
<td><span class="math inline">\(L\)</span></td>
<td><span class="math inline">\(k\)</span></td>
<td><span class="math inline">\(L\geq k\)</span></td>
<td><span class="math inline">\(E[\mathbf{z}_i\varepsilon_i]=0\)</span></td>
</tr>
<tr class="odd">
<td><strong>MLE</strong></td>
<td><span class="math inline">\(\frac{\partial \ln f(\mathbf{w}_i; \pmb{\theta})}{\partial \pmb{\theta}}\)</span></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(p\)</span></td>
<td>恰好识别</td>
<td>分布<span class="math inline">\(f(\cdot;\pmb{\theta})\)</span>正确设定</td>
</tr>
</tbody>
</table>
<p><strong>统一性证明</strong>：对于恰好识别情形（<span class="math inline">\(q=p\)</span>），三类方法均可表示为求解方程组： <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n g(\mathbf{w}_i, \pmb{\theta}) = 0
\]</span></p>
<p>解的唯一性保证了估计的一致性。对于过度识别情形（如<span class="math inline">\(L&gt;k\)</span>的2SLS），GMM通过最小化加权二次型来平衡多个矩条件。</p>
<p><strong>教学启示</strong>：这一统一视角揭示了计量估计的本质——寻找满足特定矩条件的参数值。不同方法的区别仅在于矩条件的选择和数量，而非根本原理。这种理解为我们构建更一般的估计框架奠定了基础。</p>
<hr>
</section>
</section>
<section id="广义矩方法的基本框架" class="level2">
<h2 class="anchored" data-anchor-id="广义矩方法的基本框架">15.2 广义矩方法的基本框架</h2>
<section id="矩条件的一般形式从特殊到一般的升华" class="level3">
<h3 class="anchored" data-anchor-id="矩条件的一般形式从特殊到一般的升华">矩条件的一般形式：从特殊到一般的升华</h3>
<p>广义矩方法始于一组矩条件函数： <span class="math display">\[
g(\mathbf{w}_i, \pmb{\theta}) = \begin{pmatrix} g_1(\mathbf{w}_i, \pmb{\theta}) \\ \vdots \\ g_q(\mathbf{w}_i, \pmb{\theta}) \end{pmatrix}
\]</span></p>
<p>其中<span class="math inline">\(\mathbf{w}_i\)</span>为第<span class="math inline">\(i\)</span>个观测值，<span class="math inline">\(\pmb{\theta}\)</span>为<span class="math inline">\(p\times 1\)</span>的未知参数向量，<span class="math inline">\(g\)</span>为<span class="math inline">\(q\times 1\)</span>的向量函数。</p>
<p><strong>总体矩条件</strong>假设在参数真值<span class="math inline">\(\pmb{\theta}_0\)</span>处满足： <span class="math display">\[
E[g(\mathbf{w}_i, \pmb{\theta}_0)] = 0
\]</span></p>
<p><strong>样本矩条件</strong>为其经验对应： <span class="math display">\[
\bar{g}_n(\pmb{\theta}) = \frac{1}{n}\sum_{i=1}^n g(\mathbf{w}_i, \pmb{\theta})
\]</span></p>
<p>根据大数定律，当<span class="math inline">\(n\to\infty\)</span>时，<span class="math inline">\(\bar{g}_n(\pmb{\theta}_0) \xrightarrow{p} 0\)</span>。</p>
<p><strong>识别维度分析</strong>： - 恰好识别：<span class="math inline">\(q = p\)</span>，方程有唯一解 - 过度识别：<span class="math inline">\(q &gt; p\)</span>，通常无精确解，需”平衡”条件 - 识别不足：<span class="math inline">\(q &lt; p\)</span>，无法唯一确定参数</p>
</section>
<section id="gmm估计量的定义统一框架的构建" class="level3">
<h3 class="anchored" data-anchor-id="gmm估计量的定义统一框架的构建">GMM估计量的定义：统一框架的构建</h3>
<p>在过度识别情形下，GMM通过最小化矩条件的加权二次型来估计参数：</p>
<p><strong>目标函数</strong>： <span class="math display">\[
J_n(\pmb{\theta}) = \bar{g}_n(\pmb{\theta})'\mathbf{W}_n\bar{g}_n(\pmb{\theta})
\]</span></p>
<p>其中<span class="math inline">\(\mathbf{W}_n\)</span>为<span class="math inline">\(q\times q\)</span>的对称正定权重矩阵。</p>
<p><strong>GMM估计量</strong>： <span class="math display">\[
\hat{\pmb{\theta}}_{GMM} = \arg\min_{\pmb{\theta} \in \Theta} J_n(\pmb{\theta})
\]</span></p>
<p><strong>权重矩阵的三重作用</strong>： 1. <strong>标准化</strong>：平衡不同量纲的矩条件 2. <strong>效率化</strong>：通过最优选择实现最小渐近方差 3. <strong>数值稳定化</strong>：改善优化问题的条件数</p>
<p><strong>关键性质</strong>：在恰好识别时（<span class="math inline">\(q=p\)</span>），只要<span class="math inline">\(\mathbf{W}_n\)</span>可逆，估计量不依赖于权重矩阵的选择，因为解满足<span class="math inline">\(\bar{g}_n(\hat{\pmb{\theta}})=0\)</span>，从而<span class="math inline">\(J_n(\hat{\pmb{\theta}})=0\)</span>。</p>
</section>
<section id="识别条件估计一致性的基石" class="level3">
<h3 class="anchored" data-anchor-id="识别条件估计一致性的基石">识别条件：估计一致性的基石</h3>
<section id="阶条件必要条件" class="level4">
<h4 class="anchored" data-anchor-id="阶条件必要条件">阶条件（必要条件）</h4>
<p>矩条件数量不少于参数数量：<span class="math inline">\(q \geq p\)</span></p>
</section>
<section id="秩条件充分条件" class="level4">
<h4 class="anchored" data-anchor-id="秩条件充分条件">秩条件（充分条件）</h4>
<p>矩条件函数的雅可比矩阵在真值处列满秩。定义： <span class="math display">\[
\mathbf{G}(\pmb{\theta}) = E\left[\frac{\partial g(\mathbf{w}_i, \pmb{\theta})}{\partial \pmb{\theta}'}\right]
\]</span></p>
<p>要求在<span class="math inline">\(\pmb{\theta}_0\)</span>处，<span class="math inline">\(\mathbf{G} = \mathbf{G}(\pmb{\theta}_0)\)</span>为<span class="math inline">\(q\times p\)</span>矩阵，且<span class="math inline">\(\text{rank}(\mathbf{G}) = p\)</span>。</p>
</section>
<section id="全局与局部识别" class="level4">
<h4 class="anchored" data-anchor-id="全局与局部识别">全局与局部识别</h4>
<ul>
<li>局部识别：在<span class="math inline">\(\pmb{\theta}_0\)</span>的邻域内唯一性</li>
<li>全局识别：在整个参数空间<span class="math inline">\(\Theta\)</span>内的唯一性</li>
</ul>
<p>GMM理论通常要求局部识别，而经济解释需要全局识别。非线性模型可能只满足局部识别条件。</p>
</section>
<section id="弱识别问题" class="level4">
<h4 class="anchored" data-anchor-id="弱识别问题">弱识别问题</h4>
<p>当<span class="math inline">\(\mathbf{G}(\pmb{\theta})\)</span>接近降秩时，即使满足秩条件，有限样本性质也可能很差。这在工具变量较弱时尤为常见，需要专门的诊断和稳健推断方法。</p>
</section>
</section>
<section id="统一框架下的传统方法再阐释" class="level3">
<h3 class="anchored" data-anchor-id="统一框架下的传统方法再阐释">统一框架下的传统方法再阐释</h3>
<section id="ols的gmm表述" class="level4">
<h4 class="anchored" data-anchor-id="ols的gmm表述">OLS的GMM表述</h4>
<p>矩条件：<span class="math inline">\(g^{OLS}(\mathbf{w}_i, \pmb{\beta}) = \mathbf{x}_i(y_i - \mathbf{x}_i'\pmb{\beta})\)</span></p>
<p>识别状态：恰好识别（<span class="math inline">\(q=k=p\)</span>）</p>
<p>解：<span class="math inline">\(\hat{\pmb{\beta}}_{GMM} = (n^{-1}\sum \mathbf{x}_i\mathbf{x}_i')^{-1}(n^{-1}\sum \mathbf{x}_iy_i) = \hat{\pmb{\beta}}_{OLS}\)</span></p>
</section>
<section id="sls的gmm表述" class="level4">
<h4 class="anchored" data-anchor-id="sls的gmm表述">2SLS的GMM表述</h4>
<p>矩条件：<span class="math inline">\(g^{2SLS}(\mathbf{w}_i, \pmb{\beta}) = \mathbf{z}_i(y_i - \mathbf{x}_i'\pmb{\beta})\)</span></p>
<p>识别状态：<span class="math inline">\(L=k\)</span>时恰好识别，<span class="math inline">\(L&gt;k\)</span>时过度识别</p>
<p>权重矩阵：<span class="math inline">\(\mathbf{W}_n = (n^{-1}\sum \mathbf{z}_i\mathbf{z}_i')^{-1}\)</span>（对应传统2SLS）</p>
</section>
<section id="mle的gmm表述" class="level4">
<h4 class="anchored" data-anchor-id="mle的gmm表述">MLE的GMM表述</h4>
<p>矩条件：<span class="math inline">\(g^{MLE}(\mathbf{w}_i, \pmb{\theta}) = \frac{\partial \ln f(\mathbf{w}_i; \pmb{\theta})}{\partial \pmb{\theta}}\)</span></p>
<p>识别状态：恰好识别（<span class="math inline">\(q=p\)</span>）</p>
<p>最优权重：<span class="math inline">\(\mathbf{W}_n^* = [Var(g(\mathbf{w}_i, \pmb{\theta}_0))]^{-1} = \mathcal{I}(\pmb{\theta}_0)^{-1}\)</span></p>
<p><strong>教学洞见</strong>：GMM框架的威力在于其包容性。它不替代传统方法，而是提供一个统一视角来理解它们。这种理解有助于学生在面对新问题时，能够灵活构造适当的矩条件，而非机械套用现成方法。</p>
<hr>
</section>
</section>
</section>
<section id="gmm的统计性质" class="level2">
<h2 class="anchored" data-anchor-id="gmm的统计性质">15.3 GMM的统计性质</h2>
<section id="一致性大样本下的确定性" class="level3">
<h3 class="anchored" data-anchor-id="一致性大样本下的确定性">一致性：大样本下的确定性</h3>
<p>在以下正则条件下，GMM估计量是一致的：</p>
<ol type="1">
<li><strong>参数识别</strong>：<span class="math inline">\(\pmb{\theta}_0\)</span>是唯一满足<span class="math inline">\(E[g(\mathbf{w}_i, \pmb{\theta})]=0\)</span>的参数值</li>
<li><strong>紧参数空间</strong>：<span class="math inline">\(\Theta\)</span>是紧集</li>
<li><strong>矩条件连续性</strong>：<span class="math inline">\(g(\mathbf{w}, \pmb{\theta})\)</span>关于<span class="math inline">\(\pmb{\theta}\)</span>连续</li>
<li><strong>一致收敛</strong>：<span class="math inline">\(\sup_{\pmb{\theta}\in\Theta} \|\bar{g}_n(\pmb{\theta}) - E[g(\mathbf{w}_i, \pmb{\theta})]\| \xrightarrow{p} 0\)</span></li>
<li><strong>权重矩阵收敛</strong>：<span class="math inline">\(\mathbf{W}_n \xrightarrow{p} \mathbf{W}\)</span>，<span class="math inline">\(\mathbf{W}\)</span>正定</li>
</ol>
<p>在这些条件下： <span class="math display">\[
\hat{\pmb{\theta}}_{GMM} \xrightarrow{p} \pmb{\theta}_0
\]</span></p>
<p><strong>证明思路</strong>： 1. 样本矩条件一致收敛于总体矩条件（均匀大数定律） 2. 目标函数一致收敛：<span class="math inline">\(J_n(\pmb{\theta}) \xrightarrow{p} J(\pmb{\theta}) = E[g(\mathbf{w}_i, \pmb{\theta})]'\mathbf{W}E[g(\mathbf{w}_i, \pmb{\theta})]\)</span> 3. <span class="math inline">\(J(\pmb{\theta})\)</span>在<span class="math inline">\(\pmb{\theta}_0\)</span>处唯一最小（识别条件） 4. 应用极值估计量一致性定理</p>
</section>
<section id="渐近正态性分布形态的刻画" class="level3">
<h3 class="anchored" data-anchor-id="渐近正态性分布形态的刻画">渐近正态性：分布形态的刻画</h3>
<p>附加光滑性条件后，GMM估计量具有渐近正态性：</p>
<p><strong>定理（GMM渐近分布）</strong>：假设 1. <span class="math inline">\(\pmb{\theta}_0\)</span>位于<span class="math inline">\(\Theta\)</span>内部 2. <span class="math inline">\(g(\mathbf{w}, \pmb{\theta})\)</span>在<span class="math inline">\(\pmb{\theta}_0\)</span>邻域内连续可微 3. <span class="math inline">\(\mathbf{G}(\pmb{\theta}) = E\left[\frac{\partial g(\mathbf{w}_i, \pmb{\theta})}{\partial \pmb{\theta}'}\right]\)</span>在<span class="math inline">\(\pmb{\theta}_0\)</span>处连续 4. 中心极限定理适用：<span class="math inline">\(\sqrt{n}\bar{g}_n(\pmb{\theta}_0) \xrightarrow{d} N(0, \pmb{\Omega})\)</span></p>
<p>则： <span class="math display">\[
\sqrt{n}(\hat{\pmb{\theta}}_{GMM} - \pmb{\theta}_0) \xrightarrow{d} N(0, \mathbf{V})
\]</span></p>
<p>其中： <span class="math display">\[
\mathbf{V} = (\mathbf{G}'\mathbf{W}\mathbf{G})^{-1} \mathbf{G}'\mathbf{W}\pmb{\Omega}\mathbf{W}\mathbf{G} (\mathbf{G}'\mathbf{W}\mathbf{G})^{-1}
\]</span> <span class="math inline">\(\mathbf{G} = \mathbf{G}(\pmb{\theta}_0)\)</span>，<span class="math inline">\(\pmb{\Omega} = \lim_{n\to\infty} Var(\sqrt{n}\bar{g}_n(\pmb{\theta}_0))\)</span></p>
<p><strong>证明要点</strong>： 1. 一阶条件泰勒展开： <span class="math display">\[
   0 = \frac{\partial J_n(\hat{\pmb{\theta}})}{\partial \pmb{\theta}} \approx 2\mathbf{G}_n(\tilde{\pmb{\theta}})'\mathbf{W}_n\bar{g}_n(\pmb{\theta}_0) + 2\mathbf{G}_n(\tilde{\pmb{\theta}})'\mathbf{W}_n\mathbf{G}_n(\tilde{\pmb{\theta}})(\hat{\pmb{\theta}} - \pmb{\theta}_0)
   \]</span> 2. 重新整理： <span class="math display">\[
   \sqrt{n}(\hat{\pmb{\theta}} - \pmb{\theta}_0) \approx -[\mathbf{G}_n(\tilde{\pmb{\theta}})'\mathbf{W}_n\mathbf{G}_n(\tilde{\pmb{\theta}})]^{-1}\mathbf{G}_n(\tilde{\pmb{\theta}})'\mathbf{W}_n\sqrt{n}\bar{g}_n(\pmb{\theta}_0)
   \]</span> 3. 应用Slutsky定理和中心极限定理</p>
</section>
<section id="效率与最优gmm方差最小化的追求" class="level3">
<h3 class="anchored" data-anchor-id="效率与最优gmm方差最小化的追求">效率与最优GMM：方差最小化的追求</h3>
<section id="最优权重矩阵理论" class="level4">
<h4 class="anchored" data-anchor-id="最优权重矩阵理论">最优权重矩阵理论</h4>
<p><strong>定理（最优权重）</strong>：在所有使用相同矩条件的GMM估计量中，选择<span class="math inline">\(\mathbf{W}^* = \pmb{\Omega}^{-1}\)</span>可得到最小渐近方差： <span class="math display">\[
\mathbf{V}_{opt} = (\mathbf{G}'\pmb{\Omega}^{-1}\mathbf{G})^{-1}
\]</span></p>
<p><strong>证明</strong>：对任意<span class="math inline">\(\mathbf{W}\)</span>，考虑差矩阵： <span class="math display">\[
\mathbf{V} - \mathbf{V}_{opt} = (\mathbf{G}'\mathbf{W}\mathbf{G})^{-1}\mathbf{G}'\mathbf{W}\pmb{\Sigma}\mathbf{W}\mathbf{G}(\mathbf{G}'\mathbf{W}\mathbf{G})^{-1}
\]</span> 其中<span class="math inline">\(\pmb{\Sigma} = \pmb{\Omega} - \mathbf{G}(\mathbf{G}'\pmb{\Omega}^{-1}\mathbf{G})^{-1}\mathbf{G}'\)</span>半正定。通过代数运算可证<span class="math inline">\(\mathbf{V} - \mathbf{V}_{opt}\)</span>半正定。</p>
</section>
<section id="两步骤gmm实现" class="level4">
<h4 class="anchored" data-anchor-id="两步骤gmm实现">两步骤GMM实现</h4>
<p>由于<span class="math inline">\(\pmb{\Omega}\)</span>未知，实践中采用两步骤法：</p>
<p><strong>步骤1</strong>：获取初步估计<span class="math inline">\(\tilde{\pmb{\theta}}\)</span>，使用初始权重<span class="math inline">\(\mathbf{W}_n^{(1)}\)</span>（如<span class="math inline">\(\mathbf{I}_q\)</span>或<span class="math inline">\((n^{-1}\sum \mathbf{z}_i\mathbf{z}_i')^{-1}\)</span>）</p>
<p><strong>步骤2</strong>：计算<span class="math inline">\(\pmb{\Omega}\)</span>的估计： <span class="math display">\[
\hat{\pmb{\Omega}} = \frac{1}{n}\sum_{i=1}^n g(\mathbf{w}_i, \tilde{\pmb{\theta}})g(\mathbf{w}_i, \tilde{\pmb{\theta}})'
\]</span></p>
<p>以<span class="math inline">\(\hat{\mathbf{W}}_n = \hat{\pmb{\Omega}}^{-1}\)</span>重新估计，得到<span class="math inline">\(\hat{\pmb{\theta}}_{GMM}\)</span></p>
</section>
<section id="迭代与连续更新gmm" class="level4">
<h4 class="anchored" data-anchor-id="迭代与连续更新gmm">迭代与连续更新GMM</h4>
<ul>
<li><strong>迭代GMM</strong>：反复执行步骤2直至收敛</li>
<li><strong>连续更新GMM (CUE)</strong>：同时优化参数和权重矩阵： <span class="math display">\[
\hat{\pmb{\theta}}_{CUE} = \arg\min_{\pmb{\theta}} \bar{g}_n(\pmb{\theta})'\hat{\pmb{\Omega}}(\pmb{\theta})^{-1}\bar{g}_n(\pmb{\theta})
\]</span> 其中<span class="math inline">\(\hat{\pmb{\Omega}}(\pmb{\theta}) = n^{-1}\sum g(\mathbf{w}_i, \pmb{\theta})g(\mathbf{w}_i, \pmb{\theta})'\)</span></li>
</ul>
</section>
</section>
<section id="假设检验模型设定的评估" class="level3">
<h3 class="anchored" data-anchor-id="假设检验模型设定的评估">假设检验：模型设定的评估</h3>
<section id="过度识别检验hansens-j检验" class="level4">
<h4 class="anchored" data-anchor-id="过度识别检验hansens-j检验">过度识别检验（Hansen’s J检验）</h4>
<p>检验所有<span class="math inline">\(q\)</span>个矩条件是否成立：</p>
<p><strong>原假设</strong>：<span class="math inline">\(H_0: E[g(\mathbf{w}_i, \pmb{\theta}_0)] = 0\)</span></p>
<p><strong>检验统计量</strong>： <span class="math display">\[
J_n = n\bar{g}_n(\hat{\pmb{\theta}}_{GMM})'\hat{\pmb{\Omega}}^{-1}\bar{g}_n(\hat{\pmb{\theta}}_{GMM})
\]</span></p>
<p><strong>渐近分布</strong>：<span class="math inline">\(J_n \xrightarrow{d} \chi^2_{q-p}\)</span> under <span class="math inline">\(H_0\)</span></p>
<p><strong>解释</strong>：大<span class="math inline">\(J_n\)</span>值表明矩条件可能不成立，但无法指出具体哪些条件有问题。</p>
</section>
<section id="矩条件子集检验c统计量" class="level4">
<h4 class="anchored" data-anchor-id="矩条件子集检验c统计量">矩条件子集检验（C统计量）</h4>
<p>将矩条件分为<span class="math inline">\(g = (g_1', g_2')'\)</span>，检验<span class="math inline">\(H_0: E[g_2(\mathbf{w}_i, \pmb{\theta}_0)] = 0\)</span>，已知<span class="math inline">\(E[g_1(\mathbf{w}_i, \pmb{\theta}_0)] = 0\)</span></p>
<p><strong>C统计量</strong>： <span class="math display">\[
C_n = J_n^{UR} - J_n^R \xrightarrow{d} \chi^2_{q_2}
\]</span> 其中<span class="math inline">\(J_n^{UR}\)</span>使用所有矩条件，<span class="math inline">\(J_n^R\)</span>仅使用<span class="math inline">\(g_1\)</span>，<span class="math inline">\(q_2 = \dim(g_2)\)</span></p>
</section>
<section id="参数约束检验wald检验" class="level4">
<h4 class="anchored" data-anchor-id="参数约束检验wald检验">参数约束检验（Wald检验）</h4>
<p>检验线性约束<span class="math inline">\(H_0: \mathbf{R}\pmb{\theta} = \mathbf{r}\)</span>：</p>
<p><strong>Wald统计量</strong>： <span class="math display">\[
W_n = n(\mathbf{R}\hat{\pmb{\theta}} - \mathbf{r})'[\mathbf{R}\hat{\mathbf{V}}\mathbf{R}']^{-1}(\mathbf{R}\hat{\pmb{\theta}} - \mathbf{r}) \xrightarrow{d} \chi^2_s
\]</span> 其中<span class="math inline">\(s = \text{rank}(\mathbf{R})\)</span></p>
</section>
</section>
<section id="统一视角下的传统方法性质" class="level3">
<h3 class="anchored" data-anchor-id="统一视角下的传统方法性质">统一视角下的传统方法性质</h3>
<p>在GMM框架下，传统方法的渐近性质获得统一表述：</p>
<section id="ols的渐近方差" class="level4">
<h4 class="anchored" data-anchor-id="ols的渐近方差">OLS的渐近方差</h4>
<p><span class="math display">\[
\mathbf{V}_{OLS} = (E[\mathbf{x}_i\mathbf{x}_i'])^{-1} E[\mathbf{x}_i\mathbf{x}_i'\varepsilon_i^2] (E[\mathbf{x}_i\mathbf{x}_i'])^{-1}
\]</span> 同方差时简化为<span class="math inline">\(\sigma^2(E[\mathbf{x}_i\mathbf{x}_i'])^{-1}\)</span></p>
</section>
<section id="sls的渐近方差" class="level4">
<h4 class="anchored" data-anchor-id="sls的渐近方差">2SLS的渐近方差</h4>
<p><span class="math display">\[
\mathbf{V}_{2SLS} = (E[\mathbf{z}_i\mathbf{x}_i']' \mathbf{W} E[\mathbf{z}_i\mathbf{x}_i'])^{-1} E[\mathbf{z}_i\mathbf{x}_i']' \mathbf{W} \pmb{\Omega} \mathbf{W} E[\mathbf{z}_i\mathbf{x}_i'] (E[\mathbf{z}_i\mathbf{x}_i']' \mathbf{W} E[\mathbf{z}_i\mathbf{x}_i'])^{-1}
\]</span> 其中<span class="math inline">\(\mathbf{W} = (E[\mathbf{z}_i\mathbf{z}_i'])^{-1}\)</span>，<span class="math inline">\(\pmb{\Omega} = E[\mathbf{z}_i\mathbf{z}_i'\varepsilon_i^2]\)</span></p>
</section>
<section id="mle的渐近方差" class="level4">
<h4 class="anchored" data-anchor-id="mle的渐近方差">MLE的渐近方差</h4>
<p><span class="math display">\[
\mathbf{V}_{MLE} = \mathcal{I}(\pmb{\theta}_0)^{-1}
\]</span> 这是Cramér-Rao下界，体现了MLE在正确设定下的最优性。</p>
<p><strong>总结</strong>：GMM不仅统一了估计量的构造，也统一了它们的渐近性质。所有估计量的一致性都源于矩条件的正确设定，渐近正态性都来自中心极限定理，效率差异则源于权重矩阵的选择。这种统一视角极大简化了计量理论的学习和理解。</p>
<hr>
</section>
</section>
</section>
<section id="gmm的具体应用" class="level2">
<h2 class="anchored" data-anchor-id="gmm的具体应用">15.4 GMM的具体应用</h2>
<section id="线性模型的gmm估计从传统到一般" class="level3">
<h3 class="anchored" data-anchor-id="线性模型的gmm估计从传统到一般">线性模型的GMM估计：从传统到一般</h3>
<section id="ols的异方差稳健形式" class="level4">
<h4 class="anchored" data-anchor-id="ols的异方差稳健形式">OLS的异方差稳健形式</h4>
<p>当存在异方差时，传统OLS标准误失效。在GMM框架下，我们使用更一般的协方差矩阵估计：</p>
<p>矩条件：<span class="math inline">\(g(\mathbf{w}_i, \pmb{\beta}) = \mathbf{x}_i(y_i - \mathbf{x}_i'\pmb{\beta})\)</span></p>
<p>最优权重矩阵： <span class="math display">\[
\hat{\pmb{\Omega}}^{-1} = \left(\frac{1}{n}\sum_{i=1}^n \mathbf{x}_i\mathbf{x}_i'\hat{\varepsilon}_i^2\right)^{-1}
\]</span></p>
<p>其中<span class="math inline">\(\hat{\varepsilon}_i = y_i - \mathbf{x}_i'\hat{\pmb{\beta}}_{OLS}\)</span>。对应的协方差估计为： <span class="math display">\[
\widehat{Var}(\hat{\pmb{\beta}}) = \left(\sum_{i=1}^n \mathbf{x}_i\mathbf{x}_i'\right)^{-1} \left(\sum_{i=1}^n \mathbf{x}_i\mathbf{x}_i'\hat{\varepsilon}_i^2\right) \left(\sum_{i=1}^n \mathbf{x}_i\mathbf{x}_i'\right)^{-1}
\]</span></p>
<p>这正是Eicker-Huber-White异方差稳健标准误。</p>
</section>
<section id="sls的最优gmm形式" class="level4">
<h4 class="anchored" data-anchor-id="sls的最优gmm形式">2SLS的最优GMM形式</h4>
<p>传统2SLS对应权重矩阵<span class="math inline">\(\mathbf{W}_n = (n^{-1}\sum \mathbf{z}_i\mathbf{z}_i')^{-1}\)</span>。当存在异方差时，最优GMM使用： <span class="math display">\[
\hat{\pmb{\Omega}}^{-1} = \left(\frac{1}{n}\sum_{i=1}^n \mathbf{z}_i\mathbf{z}_i'\hat{\varepsilon}_i^2\right)^{-1}
\]</span></p>
<p>其中<span class="math inline">\(\hat{\varepsilon}_i\)</span>来自第一步2SLS残差。这产生了比传统2SLS更有效的估计。</p>
</section>
</section>
<section id="非线性模型的gmm估计超越线性框架" class="level3">
<h3 class="anchored" data-anchor-id="非线性模型的gmm估计超越线性框架">非线性模型的GMM估计：超越线性框架</h3>
<section id="消费资本资产定价模型ccapm" class="level4">
<h4 class="anchored" data-anchor-id="消费资本资产定价模型ccapm">消费资本资产定价模型（CCAPM）</h4>
<p>CCAPM的欧拉方程提供天然矩条件。对于资产<span class="math inline">\(j\)</span>： <span class="math display">\[
E\left[\delta\left(\frac{C_{t+1}}{C_t}\right)^{-\gamma} R_{j,t+1} - 1 \middle| \mathcal{I}_t\right] = 0
\]</span></p>
<p>基于工具变量<span class="math inline">\(\mathbf{z}_t \in \mathcal{I}_t\)</span>，构造矩条件： <span class="math display">\[
g(\mathbf{w}_t, \pmb{\theta}) = \left[\delta\left(\frac{C_{t+1}}{C_t}\right)^{-\gamma} \mathbf{R}_{t+1} - \mathbf{1}\right] \otimes \mathbf{z}_t
\]</span></p>
<p>其中<span class="math inline">\(\pmb{\theta} = (\delta, \gamma)'\)</span>，<span class="math inline">\(\mathbf{R}_{t+1}\)</span>为资产回报向量，<span class="math inline">\(\otimes\)</span>为Kronecker积。</p>
<p><strong>估计步骤</strong>： 1. 选择工具变量（消费增长和回报的滞后项） 2. 构造样本矩条件 3. 应用GMM估计<span class="math inline">\((\delta, \gamma)\)</span> 4. J检验评估模型设定</p>
</section>
<section id="动态面板数据的gmm时间维度的挑战" class="level4">
<h4 class="anchored" data-anchor-id="动态面板数据的gmm时间维度的挑战">动态面板数据的GMM：时间维度的挑战</h4>
<p>考虑动态面板： <span class="math display">\[
y_{it} = \alpha y_{i,t-1} + \mathbf{x}_{it}'\pmb{\beta} + \eta_i + \varepsilon_{it}
\]</span></p>
<p><strong>一阶差分GMM（Arellano-Bond）</strong>： 差分消除固定效应： <span class="math display">\[
\Delta y_{it} = \alpha \Delta y_{i,t-1} + \Delta\mathbf{x}_{it}'\pmb{\beta} + \Delta\varepsilon_{it}
\]</span></p>
<p>矩条件：对<span class="math inline">\(t=2,\ldots,T\)</span>，<span class="math inline">\(s\geq 2\)</span>， <span class="math display">\[
E[y_{i,t-s}\Delta\varepsilon_{it}] = 0
\]</span></p>
<p>矩条件数量：<span class="math inline">\(\frac{T(T-1)}{2}\)</span>，随<span class="math inline">\(T\)</span>快速增长。</p>
<p><strong>系统GMM（Blundell-Bond）</strong>：结合水平方程和差分方程矩条件，提高效率。</p>
<p>水平方程矩条件：对<span class="math inline">\(t=2,\ldots,T\)</span>， <span class="math display">\[
E[\Delta y_{i,t-1}(\eta_i + \varepsilon_{it})] = 0
\]</span></p>
<p>需假设初始条件<span class="math inline">\(E[\Delta y_{i1}\eta_i] = 0\)</span>。</p>
</section>
</section>
<section id="时间序列gmm序列相关的处理" class="level3">
<h3 class="anchored" data-anchor-id="时间序列gmm序列相关的处理">时间序列GMM：序列相关的处理</h3>
<section id="异方差自相关一致hac估计" class="level4">
<h4 class="anchored" data-anchor-id="异方差自相关一致hac估计">异方差自相关一致（HAC）估计</h4>
<p>当矩条件存在序列相关时，<span class="math inline">\(\pmb{\Omega} = \sum_{j=-\infty}^{\infty} \Gamma_j\)</span>，其中<span class="math inline">\(\Gamma_j = E[g_t g_{t-j}']\)</span>。</p>
<p><strong>Newey-West估计量</strong>： <span class="math display">\[
\hat{\pmb{\Omega}}_{HAC} = \hat{\Gamma}_0 + \sum_{j=1}^{m} w(j,m)(\hat{\Gamma}_j + \hat{\Gamma}_j')
\]</span></p>
<p>常用核函数： - Bartlett：<span class="math inline">\(w(j,m) = 1 - \frac{j}{m+1}\)</span> - Parzen：<span class="math inline">\(w(j,m) = \begin{cases} 1 - 6\left(\frac{j}{m}\right)^2 + 6\left(\frac{j}{m}\right)^3, &amp; 0 \leq j \leq m/2 \\ 2(1-j/m)^3, &amp; m/2 &lt; j \leq m \end{cases}\)</span> - Quadratic Spectral：<span class="math inline">\(w(j,m) = \frac{25}{12\pi^2(j/m)^2}\left[\frac{\sin(6\pi j/5m)}{6\pi j/5m} - \cos(6\pi j/5m)\right]\)</span></p>
<p>带宽选择：<span class="math inline">\(m = \lfloor 4(n/100)^{2/9} \rfloor\)</span>（Newey-West建议）</p>
</section>
<section id="长面板与短面板的不同策略" class="level4">
<h4 class="anchored" data-anchor-id="长面板与短面板的不同策略">长面板与短面板的不同策略</h4>
<p><strong>短面板</strong>（<span class="math inline">\(T\)</span>固定，<span class="math inline">\(N\to\infty\)</span>）： - 关注截面相关 - 使用截面聚类标准误：<span class="math inline">\(\hat{\pmb{\Omega}} = \sum_{i=1}^N g_i g_i'\)</span></p>
<p><strong>长面板</strong>（<span class="math inline">\(N\)</span>固定，<span class="math inline">\(T\to\infty\)</span>）： - 关注时间序列性质 - 使用HAC标准误 - 可能面临结构变化问题</p>
</section>
</section>
<section id="应用实例解析" class="level3">
<h3 class="anchored" data-anchor-id="应用实例解析">应用实例解析</h3>
<section id="实例1教育回报估计card-1995" class="level4">
<h4 class="anchored" data-anchor-id="实例1教育回报估计card-1995">实例1：教育回报估计（Card, 1995）</h4>
<ul>
<li>内生变量：教育年限</li>
<li>工具变量：大学 proximity</li>
<li>矩条件：<span class="math inline">\(E[proximity_i \cdot (ln wage_i - \beta_0 - \beta_1 educ_i - \mathbf{x}_i'\pmb{\beta}_2)] = 0\)</span></li>
<li>扩展：加入更多工具变量（父母教育等）形成过度识别系统</li>
</ul>
</section>
<section id="实例2货币政策反应函数估计" class="level4">
<h4 class="anchored" data-anchor-id="实例2货币政策反应函数估计">实例2：货币政策反应函数估计</h4>
<ul>
<li>泰勒规则：<span class="math inline">\(i_t = \alpha + \beta\pi_t + \gamma y_t + \varepsilon_t\)</span></li>
<li>内生性：利率与通胀、产出相互影响</li>
<li>工具变量：通胀和产出的滞后项、外生冲击</li>
<li>矩条件：<span class="math inline">\(E[\mathbf{z}_t(i_t - \alpha - \beta\pi_t - \gamma y_t)] = 0\)</span></li>
</ul>
<p><strong>实践启示</strong>：GMM的应用关键在于矩条件的合理构造。好的矩条件应同时满足： 1. 经济理论合理性 2. 统计识别能力 3. 外生性保障 4. 计算可行性</p>
<p>从简单模型开始，逐步增加复杂性，是应用GMM的明智策略。</p>
<hr>
</section>
</section>
</section>
<section id="实践中的gmm问题与对策" class="level2">
<h2 class="anchored" data-anchor-id="实践中的gmm问题与对策">15.5 实践中的GMM：问题与对策</h2>
<section id="弱工具变量问题识别不足的挑战" class="level3">
<h3 class="anchored" data-anchor-id="弱工具变量问题识别不足的挑战">弱工具变量问题：识别不足的挑战</h3>
<p>弱工具变量指<span class="math inline">\(\mathbf{z}_i\)</span>与<span class="math inline">\(\mathbf{x}_i\)</span>相关性微弱，这导致：</p>
<p><strong>有限样本问题</strong>： 1. 估计量偏误大：即使渐近无偏，小样本偏误可能严重 2. 近似正态性差：分布高度非正态，尤其当<span class="math inline">\(L\)</span>大时 3. 标准误低估：常规推断严重扭曲</p>
<p><strong>诊断工具</strong>： 1. <strong>第一阶段F统计量</strong>：经验法则要求<span class="math inline">\(F &gt; 10\)</span> 2. <strong>Shea’s partial R²</strong>：度量每个内生变量的识别强度 3. <strong>Cragg-Donald统计量</strong>：检验弱识别的正规方法 4. <strong>Stock-Yogo临界值</strong>：基于最大相对偏误或Wald检验扭曲的临界值</p>
<p><strong>改进估计量</strong>： 1. <strong>LIML（有限信息最大似然）</strong>：对弱IV更稳健 2. <strong>Fuller修正估计量</strong>：<span class="math inline">\(\hat{\pmb{\beta}}_{Fuller} = (1-c/(n-L))\hat{\pmb{\beta}}_{LIML}\)</span>，<span class="math inline">\(c\)</span>为常数 3. <strong>连续更新GMM</strong>：对弱识别更稳健 4. <strong>Jackknife IV</strong>：消除许多弱IV的偏误</p>
<p><strong>稳健推断方法</strong>： - <strong>Anderson-Rubin检验</strong>：对弱IV稳健，检验<span class="math inline">\(\beta = \beta_0\)</span> - <strong>条件似然比检验</strong>：在弱识别下保持正确大小 - <strong>识别鲁棒置信区间</strong>：通过逆检验构造，如： <span class="math display">\[
  CI = {\beta_0: AR(\beta_0) \leq \chi^2_{1-\alpha}(1)}
\]</span></p>
</section>
<section id="权重矩阵估计效率与稳定的平衡" class="level3">
<h3 class="anchored" data-anchor-id="权重矩阵估计效率与稳定的平衡">权重矩阵估计：效率与稳定的平衡</h3>
<section id="一步与两步gmm的比较" class="level4">
<h4 class="anchored" data-anchor-id="一步与两步gmm的比较">一步与两步GMM的比较</h4>
<p><strong>一步GMM</strong>（使用固定权重）： - 优点：计算简单，避免第一步估计误差传播 - 缺点：通常非最优，效率损失 - 适用：大样本，计算资源有限</p>
<p><strong>两步GMM</strong>（使用估计的最优权重）： - 优点：渐近最优，效率高 - 缺点：有限样本偏误可能更大，尤其当<span class="math inline">\(q\)</span>大时 - 适用：样本量足够大，追求效率</p>
</section>
<section id="迭代gmm的实践" class="level4">
<h4 class="anchored" data-anchor-id="迭代gmm的实践">迭代GMM的实践</h4>
<p>迭代至收敛的过程： 1. <span class="math inline">\(\hat{\pmb{\theta}}^{(0)} = \text{一步GMM估计}\)</span> 2. For <span class="math inline">\(k=1,2,\ldots\)</span>: - <span class="math inline">\(\hat{\pmb{\Omega}}^{(k)} = n^{-1}\sum g(\mathbf{w}_i, \hat{\pmb{\theta}}^{(k-1)})g(\mathbf{w}_i, \hat{\pmb{\theta}}^{(k-1)})'\)</span> - <span class="math inline">\(\hat{\pmb{\theta}}^{(k)} = \arg\min_{\pmb{\theta}} \bar{g}_n(\pmb{\theta})'[\hat{\pmb{\Omega}}^{(k)}]^{-1}\bar{g}_n(\pmb{\theta})\)</span> 3. 当<span class="math inline">\(\|\hat{\pmb{\theta}}^{(k)} - \hat{\pmb{\theta}}^{(k-1)}\| &lt; \epsilon\)</span>时停止</p>
<p><strong>收敛性</strong>：通常3-5次迭代足够。迭代GMM与两步GMM渐近等价，但有限样本性质可能更好。</p>
</section>
<section id="高维权重矩阵问题" class="level4">
<h4 class="anchored" data-anchor-id="高维权重矩阵问题">高维权重矩阵问题</h4>
<p>当<span class="math inline">\(q\)</span>很大时，<span class="math inline">\(\hat{\pmb{\Omega}}\)</span>的估计可能不稳定。解决方法：</p>
<ol type="1">
<li><p><strong>收缩估计</strong>： <span class="math display">\[
\hat{\pmb{\Omega}}_{shrink} = \lambda \hat{\pmb{\Omega}} + (1-\lambda)\mathbf{I}_q
\]</span></p></li>
<li><p><strong>因子结构</strong>：假设<span class="math inline">\(\pmb{\Omega} = \mathbf{F}\mathbf{F}' + \mathbf{D}\)</span>，其中<span class="math inline">\(\mathbf{D}\)</span>为对角阵</p></li>
<li><p><strong>正则化</strong>：加入惩罚项<span class="math inline">\(\rho\|\pmb{\Omega}^{-1}\|_*\)</span>，其中<span class="math inline">\(\|\cdot\|_*\)</span>为核范数</p></li>
</ol>
</section>
</section>
<section id="矩条件选择数量与质量的权衡" class="level3">
<h3 class="anchored" data-anchor-id="矩条件选择数量与质量的权衡">矩条件选择：数量与质量的权衡</h3>
<section id="冗余矩条件问题" class="level4">
<h4 class="anchored" data-anchor-id="冗余矩条件问题">冗余矩条件问题</h4>
<p><strong>定义</strong>：矩条件<span class="math inline">\(g_j\)</span>冗余，如果存在函数<span class="math inline">\(h\)</span>使<span class="math inline">\(g_j = h(g_1,\ldots,g_{j-1},g_{j+1},\ldots,g_q)\)</span></p>
<p><strong>影响</strong>： - 不改变一致性 - 增加渐近方差 - 恶化有限样本性质 - 使权重矩阵估计不稳定</p>
<p><strong>检测方法</strong>： 1. <strong>秩检验</strong>：检验<span class="math inline">\(\pmb{\Omega}\)</span>是否满秩 2. <strong>特征值分析</strong>：小特征值对应的矩条件可能冗余 3. <strong>逐步选择</strong>：基于信息准则增加/删除矩条件</p>
</section>
<section id="矩条件数量优化" class="level4">
<h4 class="anchored" data-anchor-id="矩条件数量优化">矩条件数量优化</h4>
<p><strong>偏差-方差权衡</strong>： - 矩条件少：方差大，但偏误小（对错误设定稳健） - 矩条件多：方差小（渐近），但有限样本偏误大，对错误设定敏感</p>
<p><strong>选择准则</strong>： 1. <strong>Hansen’s J准则</strong>：选择使J统计量最小的子集（需调整自由度） 2. <strong>信息准则</strong>： <span class="math display">\[
   IC(q) = J_n(q) + q \cdot \text{penalty}(n)
\]</span> 如：<span class="math inline">\(\text{BIC penalty} = \ln n\)</span>，<span class="math inline">\(\text{AIC penalty} = 2\)</span> 3. <strong>交叉验证</strong>：将样本分为训练集和验证集</p>
</section>
<section id="降维技术" class="level4">
<h4 class="anchored" data-anchor-id="降维技术">降维技术</h4>
<ol type="1">
<li><p><strong>主成分GMM</strong>：对矩条件进行PCA，保留主要成分 <span class="math display">\[
\tilde{g}_i = \mathbf{V}_r' g_i
\]</span> 其中<span class="math inline">\(\mathbf{V}_r\)</span>为前<span class="math inline">\(r\)</span>个特征向量</p></li>
<li><p><strong>因子GMM</strong>：假设<span class="math inline">\(g_i = \mathbf{\Lambda} f_i + u_i\)</span>，使用因子得分作为新矩条件</p></li>
<li><p><strong>分组平均</strong>：将相关矩条件分组平均，减少数量</p></li>
</ol>
</section>
</section>
<section id="数值优化问题" class="level3">
<h3 class="anchored" data-anchor-id="数值优化问题">数值优化问题</h3>
<p>GMM估计需要数值优化，可能遇到：</p>
<p><strong>局部最小值</strong>：目标函数<span class="math inline">\(J_n(\pmb{\theta})\)</span>可能非凸</p>
<p><strong>解决策略</strong>： 1. <strong>多起点搜索</strong>：从不同初始值开始，选择最小结果 2. <strong>全局优化算法</strong>：模拟退火、遗传算法 3. <strong>参数变换</strong>：将约束优化转为无约束优化</p>
<p><strong>梯度信息利用</strong>： 解析梯度加速收敛： <span class="math display">\[
\frac{\partial J_n}{\partial \pmb{\theta}} = 2\mathbf{G}_n(\pmb{\theta})'\mathbf{W}_n\bar{g}_n(\pmb{\theta})
\]</span></p>
<p><strong>收敛准则</strong>： 1. 参数变化：<span class="math inline">\(\|\pmb{\theta}^{(k)} - \pmb{\theta}^{(k-1)}\| &lt; \epsilon_1\)</span> 2. 函数值变化：<span class="math inline">\(|J_n^{(k)} - J_n^{(k-1)}| &lt; \epsilon_2\)</span> 3. 梯度大小：<span class="math inline">\(\|\partial J_n/\partial \pmb{\theta}\| &lt; \epsilon_3\)</span></p>
</section>
<section id="软件实践建议" class="level3">
<h3 class="anchored" data-anchor-id="软件实践建议">软件实践建议</h3>
<ol type="1">
<li><strong>从简单开始</strong>：先用OLS/2SLS获得初始值</li>
<li><strong>监控收敛</strong>：记录每次迭代的参数值和目标函数值</li>
<li><strong>敏感性分析</strong>：检查不同权重矩阵、不同矩条件选择的结果稳定性</li>
<li><strong>诊断检验</strong>：必须报告J检验、第一阶段F统计量等</li>
<li><strong>稳健标准误</strong>：总是报告异方差/自相关稳健的标准误</li>
</ol>
<p><strong>黄金法则</strong>：如果GMM结果与简单方法差异巨大，应深入探究原因，而非简单接受GMM结果。</p>
<hr>
</section>
</section>
<section id="gmm的扩展与前沿" class="level2">
<h2 class="anchored" data-anchor-id="gmm的扩展与前沿">15.6 GMM的扩展与前沿</h2>
<section id="经验似然方法非参数似然的视角" class="level3">
<h3 class="anchored" data-anchor-id="经验似然方法非参数似然的视角">经验似然方法：非参数似然的视角</h3>
<p>经验似然（Empirical Likelihood, EL）提供了一种非参数似然框架，与GMM有深刻联系。</p>
<section id="基本思想" class="level4">
<h4 class="anchored" data-anchor-id="基本思想">基本思想</h4>
<p>在满足矩条件的约束下，最大化非参数似然： <span class="math display">\[
\max_{p_1,\ldots,p_n} \prod_{i=1}^n p_i
\]</span> 约束： 1. <span class="math inline">\(p_i \geq 0\)</span>，<span class="math inline">\(\sum p_i = 1\)</span> 2. <span class="math inline">\(\sum_{i=1}^n p_i g(\mathbf{w}_i, \pmb{\theta}) = 0\)</span></p>
<p><strong>拉格朗日函数</strong>： <span class="math display">\[
\mathcal{L} = \sum_{i=1}^n \ln p_i - \mu(\sum p_i - 1) - n\pmb{\lambda}'\sum p_i g(\mathbf{w}_i, \pmb{\theta})
\]</span></p>
<p>解得： <span class="math display">\[
p_i = \frac{1}{n} \cdot \frac{1}{1 + \pmb{\lambda}' g(\mathbf{w}_i, \pmb{\theta})}
\]</span> 其中<span class="math inline">\(\pmb{\lambda}\)</span>满足： <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n \frac{g(\mathbf{w}_i, \pmb{\theta})}{1 + \pmb{\lambda}' g(\mathbf{w}_i, \pmb{\theta})} = 0
\]</span></p>
</section>
<section id="与gmm的关系" class="level4">
<h4 class="anchored" data-anchor-id="与gmm的关系">与GMM的关系</h4>
<p><strong>一阶等价性</strong>：经验似然估计量<span class="math inline">\(\hat{\pmb{\theta}}_{EL}\)</span>与连续更新GMM估计量<span class="math inline">\(\hat{\pmb{\theta}}_{CUE}\)</span>一阶渐近等价。</p>
<p><strong>二阶优势</strong>：经验似然有二阶效率性质（Bartlett可修正性）： 1. 置信区间覆盖精度更高 2. 不需要估计<span class="math inline">\(\pmb{\Omega}\)</span> 3. 自动产生正权重<span class="math inline">\(p_i\)</span></p>
<p><strong>数值实现</strong>：双重优化问题： <span class="math display">\[
\hat{\pmb{\theta}}_{EL} = \arg\min_{\pmb{\theta}} \max_{\pmb{\lambda}} \sum_{i=1}^n \ln(1 + \pmb{\lambda}' g(\mathbf{w}_i, \pmb{\theta}))
\]</span></p>
</section>
<section id="扩展形式" class="level4">
<h4 class="anchored" data-anchor-id="扩展形式">扩展形式</h4>
<ol type="1">
<li><strong>指数倾斜经验似然</strong>：使用KL散度惩罚</li>
<li><strong>广义经验似然</strong>：包含CUE、EL等作为特例</li>
<li><strong>贝叶斯经验似然</strong>：结合先验信息</li>
</ol>
</section>
</section>
<section id="局部识别与弱识别渐近理论的扩展" class="level3">
<h3 class="anchored" data-anchor-id="局部识别与弱识别渐近理论的扩展">局部识别与弱识别：渐近理论的扩展</h3>
<section id="弱收敛理论框架" class="level4">
<h4 class="anchored" data-anchor-id="弱收敛理论框架">弱收敛理论框架</h4>
<p>当识别强度随样本量衰减时，需要新的渐近理论。</p>
<p><strong>弱识别设定</strong>：设<span class="math inline">\(\mathbf{G}(\pmb{\theta}_0) = \mathbf{G}_0/\sqrt{n}\)</span>，其中<span class="math inline">\(\mathbf{G}_0\)</span>固定。</p>
<p>此时，传统渐近理论失效： 1. GMM估计量不一致 2. 收敛速度为<span class="math inline">\(\sqrt{n}\)</span>，但极限分布非正态 3. 标准检验扭曲严重</p>
<p><strong>Staiger-Stock近似</strong>：在弱IV下，2SLS的近似分布： <span class="math display">\[
\hat{\beta}_{2SLS} - \beta_0 \approx \frac{\pmb{\pi}' \mathbf{Z}'\varepsilon/n}{\pmb{\pi}'\mathbf{Z}'\mathbf{Z}\pmb{\pi}/n} + \text{非正态项}
\]</span></p>
</section>
<section id="稳健推断方法" class="level4">
<h4 class="anchored" data-anchor-id="稳健推断方法">稳健推断方法</h4>
<p><strong>Anderson-Rubin检验</strong>： 原假设<span class="math inline">\(H_0: \beta = \beta_0\)</span> <span class="math display">\[
AR(\beta_0) = \frac{(y - \mathbf{X}\beta_0)'\mathbf{P}_Z(y - \mathbf{X}\beta_0)/q}{(y - \mathbf{X}\beta_0)'(\mathbf{M}_Z)(y - \mathbf{X}\beta_0)/(n-q)}
\]</span> 在<span class="math inline">\(H_0\)</span>下，<span class="math inline">\(AR(\beta_0) \xrightarrow{d} \chi^2_q/q\)</span>，即使存在弱IV。</p>
<p><strong>条件似然比检验</strong>： <span class="math display">\[
CLR(\beta_0) = \frac{1}{2}\left[AR(\beta_0) - rk + \sqrt{(AR(\beta_0) - rk)^2 + 4\cdot LR(\beta_0)\cdot rk}\right]
\]</span> 其中<span class="math inline">\(rk\)</span>为Cragg-Donald统计量，<span class="math inline">\(LR\)</span>为似然比统计量。</p>
<p><strong>识别鲁棒置信区间</strong>： 通过逆检验构造： <span class="math display">\[
CI_{1-\alpha} = {\beta_0: \text{test}(\beta_0) \leq c_{1-\alpha}}
\]</span> 常用检验包括AR、Kleibergen、CLR等。</p>
</section>
<section id="许多弱工具变量" class="level4">
<h4 class="anchored" data-anchor-id="许多弱工具变量">许多弱工具变量</h4>
<p>当<span class="math inline">\(L\)</span>很大但每个工具都很弱时：</p>
<p><strong>正则化方法</strong>： 1. <strong>岭回归第一阶段</strong>：<span class="math inline">\(\hat{\pmb{\pi}} = (\mathbf{Z}'\mathbf{Z} + \lambda\mathbf{I})^{-1}\mathbf{Z}'\mathbf{X}\)</span> 2. <strong>主成分IV</strong>：使用<span class="math inline">\(\mathbf{Z}\)</span>的主成分作为新工具 3. <strong>LASSO选择</strong>：选择相关工具变量</p>
<p><strong>Jackknife IV</strong>： <span class="math display">\[
\hat{\beta}_{JIVE} = \frac{\sum_i \mathbf{x}_{(i)}' y_i}{\sum_i \mathbf{x}_{(i)}' \mathbf{x}_i}
\]</span> 其中<span class="math inline">\(\mathbf{x}_{(i)}\)</span>使用除<span class="math inline">\(i\)</span>外所有观测估计的第一阶段预测值，避免”自身预测”偏误。</p>
</section>
</section>
<section id="高维gmm大q时代的挑战" class="level3">
<h3 class="anchored" data-anchor-id="高维gmm大q时代的挑战">高维GMM：大<span class="math inline">\(q\)</span>时代的挑战</h3>
<p>当<span class="math inline">\(q\)</span>很大，可能<span class="math inline">\(q &gt; n\)</span>时：</p>
<section id="正则化gmm" class="level4">
<h4 class="anchored" data-anchor-id="正则化gmm">正则化GMM</h4>
<ol type="1">
<li><p><strong>弹性网络惩罚</strong>： <span class="math display">\[
\min_{\pmb{\theta}} \bar{g}_n(\pmb{\theta})'\mathbf{W}_n\bar{g}_n(\pmb{\theta}) + \lambda_1\|\pmb{\theta}\|_1 + \lambda_2\|\pmb{\theta}\|_2^2
\]</span></p></li>
<li><p><strong>稀疏GMM</strong>：假设只有少量矩条件重要，使用L1惩罚选择： <span class="math display">\[
\min_{\pmb{\theta}} \bar{g}_n(\pmb{\theta})'\mathbf{W}_n\bar{g}_n(\pmb{\theta}) + \lambda\sum_{j=1}^q |\theta_j|
\]</span></p></li>
<li><p><strong>两步选择</strong>：</p>
<ul>
<li>第一步：用LASSO选择活跃矩条件</li>
<li>第二步：用选定矩条件进行GMM估计</li>
</ul></li>
</ol>
</section>
<section id="去偏推断" class="level4">
<h4 class="anchored" data-anchor-id="去偏推断">去偏推断</h4>
<p>高维下，直接推断可能偏误。去偏（debiased）GMM： <span class="math display">\[
\hat{\pmb{\theta}}^{db} = \hat{\pmb{\theta}} - \hat{\mathbf{\Theta}}\bar{g}_n(\hat{\pmb{\theta}})
\]</span> 其中<span class="math inline">\(\hat{\mathbf{\Theta}}\)</span>为<span class="math inline">\(\mathbf{G}\)</span>的估计的广义逆。</p>
<p>渐近分布： <span class="math display">\[
\sqrt{n}(\hat{\pmb{\theta}}^{db} - \pmb{\theta}_0) \xrightarrow{d} N(0, \mathbf{\Theta}\pmb{\Omega}\mathbf{\Theta}')
\]</span></p>
</section>
<section id="自助法推断" class="level4">
<h4 class="anchored" data-anchor-id="自助法推断">自助法推断</h4>
<p>高维下渐近近似可能不准确，可使用：</p>
<ol type="1">
<li><strong>配对自助法</strong>：重采样<span class="math inline">\((\mathbf{w}_i, \mathbf{z}_i)\)</span>对</li>
<li><strong>残差自助法</strong>：固定<span class="math inline">\(\mathbf{X},\mathbf{Z}\)</span>，重抽样残差</li>
<li><strong>子抽样</strong>：使用小子样本计算分布</li>
</ol>
</section>
</section>
<section id="机器学习与gmm的结合" class="level3">
<h3 class="anchored" data-anchor-id="机器学习与gmm的结合">机器学习与GMM的结合</h3>
<section id="基于机器学习的矩条件" class="level4">
<h4 class="anchored" data-anchor-id="基于机器学习的矩条件">基于机器学习的矩条件</h4>
<ol type="1">
<li><p><strong>神经网络矩条件</strong>：用神经网络学习矩条件函数 <span class="math display">\[
g_{NN}(\mathbf{w}_i, \pmb{\theta}) = \phi(\mathbf{w}_i; \pmb{\omega}) \cdot (y_i - m(\mathbf{x}_i; \pmb{\theta}))
\]</span> 其中<span class="math inline">\(\phi\)</span>为神经网络，<span class="math inline">\(\pmb{\omega}\)</span>为网络参数</p></li>
<li><p><strong>随机森林IV</strong>：用随机森林预测内生变量</p></li>
<li><p><strong>深度学习GMM</strong>：用深度学习模型构建矩条件</p></li>
</ol>
</section>
<section id="双重机器学习" class="level4">
<h4 class="anchored" data-anchor-id="双重机器学习">双重机器学习</h4>
<ol type="1">
<li>用机器学习估计倾向得分或条件期望</li>
<li>构造基于估计量的矩条件</li>
<li>应用GMM估计结构参数</li>
</ol>
<p><strong>示例</strong>：处理效应估计： <span class="math display">\[
g(\mathbf{w}_i, \theta) = \frac{D_i(Y_i - \hat{\mu}_1(\mathbf{X}_i))}{\hat{\pi}(\mathbf{X}_i)} - \frac{(1-D_i)(Y_i - \hat{\mu}_0(\mathbf{X}_i))}{1-\hat{\pi}(\mathbf{X}_i)} + \hat{\mu}_1(\mathbf{X}_i) - \hat{\mu}_0(\mathbf{X}_i) - \theta
\]</span> 其中<span class="math inline">\(\hat{\pi},\hat{\mu}_0,\hat{\mu}_1\)</span>由机器学习估计。</p>
</section>
<section id="因果推断中的gmm" class="level4">
<h4 class="anchored" data-anchor-id="因果推断中的gmm">因果推断中的GMM</h4>
<ol type="1">
<li><strong>双重稳健估计</strong>：结合倾向得分和结果回归</li>
<li><strong>动态处理效应</strong>：使用序列矩条件</li>
<li><strong>分位数处理效应</strong>：基于分位数矩条件</li>
</ol>
</section>
</section>
<section id="计算前沿高效算法与软件" class="level3">
<h3 class="anchored" data-anchor-id="计算前沿高效算法与软件">计算前沿：高效算法与软件</h3>
<section id="现代优化算法" class="level4">
<h4 class="anchored" data-anchor-id="现代优化算法">现代优化算法</h4>
<ol type="1">
<li><p><strong>随机梯度下降</strong>：适用于大规模问题 <span class="math display">\[
\pmb{\theta}_{t+1} = \pmb{\theta}_t - \eta_t \nabla J_n(\pmb{\theta}_t)
\]</span></p></li>
<li><p><strong>自适应矩估计（Adam）</strong>：结合动量与自适应学习率</p></li>
<li><p><strong>二阶方法</strong>：拟牛顿法（BFGS）、共轭梯度法</p></li>
</ol>
</section>
<section id="分布式计算" class="level4">
<h4 class="anchored" data-anchor-id="分布式计算">分布式计算</h4>
<p>对于海量数据： 1. <strong>分块GMM</strong>：将数据分块，分别计算矩条件，再合并 2. <strong>MapReduce实现</strong>：mapper计算个体矩条件，reducer加总 3. <strong>随机化算法</strong>：使用子样本加速计算</p>
</section>
<section id="软件进展" class="level4">
<h4 class="anchored" data-anchor-id="软件进展">软件进展</h4>
<ol type="1">
<li><strong>专用包</strong>：<code>gmm</code> (R), <code>linearmodels</code> (Python), <code>ivreg2</code> (Stata)</li>
<li><strong>自动微分</strong>：使用<code>JAX</code>、<code>PyTorch</code>等计算精确梯度</li>
<li><strong>GPU加速</strong>：利用GPU并行计算矩条件</li>
</ol>
<p><strong>未来方向</strong>：GMM框架将继续融合机器学习、高维统计、分布式计算等技术，成为处理复杂经济计量问题的核心工具。</p>
<hr>
</section>
</section>
</section>
<section id="本章总结" class="level2">
<h2 class="anchored" data-anchor-id="本章总结">本章总结</h2>
<p>广义矩方法代表了计量经济学估计思想的集大成与统一。通过本章的学习，我们应建立起以下核心认知体系：</p>
<section id="一统一性认知" class="level3">
<h3 class="anchored" data-anchor-id="一统一性认知">一、统一性认知</h3>
<p>GMM不是孤立的估计技术，而是<strong>统一的理论框架</strong>： 1. <strong>方法统一</strong>：OLS、2SLS、MLE都是GMM的特例，区别仅在于矩条件的选择和数量 2. <strong>理论统一</strong>：所有估计量的一致性源于矩条件的正确设定，渐近正态性来自中心极限定理 3. <strong>推断统一</strong>：假设检验都基于相同的渐近分布理论</p>
<p>这种统一性极大简化了计量经济学的理论体系，使学习者能够”以简驭繁”。</p>
</section>
<section id="二实践性智慧" class="level3">
<h3 class="anchored" data-anchor-id="二实践性智慧">二、实践性智慧</h3>
<p>应用GMM需要平衡多个维度： 1. <strong>假设与效率</strong>：更强的假设（更多矩条件）带来潜在效率增益，但也增加误设风险 2. <strong>有限与无限样本</strong>：渐近最优性在有限样本下可能不成立，需关注弱工具变量等问题 3. <strong>简洁与丰富</strong>：模型应足够丰富以捕捉重要特征，又足够简洁以避免过拟合</p>
<p><strong>实用准则</strong>： - 从简单模型（OLS/2SLS）开始，作为基准 - 逐步增加矩条件，监控J检验和估计值稳定性 - 报告多种标准误（传统、异方差稳健、聚类稳健等） - 进行敏感性分析和稳健性检验</p>
</section>
<section id="三前沿性视野" class="level3">
<h3 class="anchored" data-anchor-id="三前沿性视野">三、前沿性视野</h3>
<p>GMM仍在不断发展中： 1. <strong>理论前沿</strong>：弱识别、高维GMM、非标准渐近理论 2. <strong>方法前沿</strong>：与机器学习结合、因果推断应用、贝叶斯GMM 3. <strong>计算前沿</strong>：分布式算法、自动微分、GPU加速</p>
<p>这些发展使GMM能够应对日益复杂的经济数据和问题。</p>
</section>
<section id="四批判性思考" class="level3">
<h3 class="anchored" data-anchor-id="四批判性思考">四、批判性思考</h3>
<p>尽管强大，GMM并非”银弹”： 1. <strong>矩条件的质量决定一切</strong>：垃圾进，垃圾出 2. <strong>有限样本性质可能不佳</strong>：尤其当工具变量弱或矩条件多时 3. <strong>计算复杂性</strong>：可能需要专门优化算法 4. <strong>解释透明性</strong>：过度复杂的矩条件可能难以解释</p>
</section>
<section id="五学习建议" class="level3">
<h3 class="anchored" data-anchor-id="五学习建议">五、学习建议</h3>
<ol type="1">
<li><strong>夯实基础</strong>：深入理解OLS、2SLS、MLE的矩条件本质</li>
<li><strong>循序渐进</strong>：从恰好识别到过度识别，从同方差到异方差</li>
<li><strong>重视实践</strong>：通过实际数据分析掌握GMM的应用技巧</li>
<li><strong>关注前沿</strong>：了解GMM的最新发展，但不必盲目追求复杂方法</li>
</ol>
<p><strong>最终启示</strong>：GMM的精髓不在于复杂的数学，而在于其<strong>统一的思想</strong>——将经济理论转化为可检验的矩条件，用数据验证理论，用理论解释数据。这一思想将伴随您整个计量经济学学习与研究历程。</p>
<hr>
</section>
</section>
<section id="进一步阅读" class="level2">
<h2 class="anchored" data-anchor-id="进一步阅读">进一步阅读</h2>
<section id="经典文献" class="level3">
<h3 class="anchored" data-anchor-id="经典文献">经典文献</h3>
<ol type="1">
<li><strong>奠基之作</strong>：
<ul>
<li>Hansen, L. P. (1982). Large sample properties of generalized method of moments estimators. <em>Econometrica</em>, 50(4), 1029-1054.</li>
</ul></li>
<li><strong>权威教材</strong>：
<ul>
<li>Hayashi, F. (2000). <em>Econometrics</em>. Princeton University Press. (第3章)</li>
<li>Wooldridge, J. M. (2010). <em>Econometric Analysis of Cross Section and Panel Data</em> (2nd ed.). MIT Press. (第8、14章)</li>
<li>Cameron, A. C., &amp; Trivedi, P. K. (2005). <em>Microeconometrics: Methods and Applications</em>. Cambridge University Press. (第6章)</li>
</ul></li>
<li><strong>应用指南</strong>：
<ul>
<li>Baum, C. F. (2006). <em>An Introduction to Modern Econometrics Using Stata</em>. Stata Press.</li>
<li>Angrist, J. D., &amp; Pischke, J.-S. (2009). <em>Mostly Harmless Econometrics</em>. Princeton University Press.</li>
</ul></li>
</ol>
</section>
<section id="前沿研究" class="level3">
<h3 class="anchored" data-anchor-id="前沿研究">前沿研究</h3>
<ol type="1">
<li><strong>弱识别与推断</strong>：
<ul>
<li>Stock, J. H., Wright, J. H., &amp; Yogo, M. (2002). A survey of weak instruments and weak identification in generalized method of moments. <em>Journal of Business &amp; Economic Statistics</em>, 20(4), 518-529.</li>
<li>Andrews, I., Stock, J. H., &amp; Sun, L. (2019). Weak instruments in instrumental variables regression: Theory and practice. <em>Annual Review of Economics</em>, 11, 727-753.</li>
</ul></li>
<li><strong>高维GMM</strong>：
<ul>
<li>Caner, M., &amp; Zhang, H. H. (2014). Adaptive elastic net for generalized method of moments. <em>Journal of Business &amp; Economic Statistics</em>, 32(1), 30-47.</li>
<li>Chang, J., Chen, S. X., &amp; Chen, X. (2015). High dimensional generalized empirical likelihood for moment restrictions with dependent data. <em>Journal of Econometrics</em>, 185(1), 283-304.</li>
</ul></li>
<li><strong>机器学习结合</strong>：
<ul>
<li>Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., &amp; Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. <em>The Econometrics Journal</em>, 21(1), C1-C68.</li>
</ul></li>
</ol>
</section>
<section id="软件资源" class="level3">
<h3 class="anchored" data-anchor-id="软件资源">软件资源</h3>
<ol type="1">
<li><strong>R包</strong>：
<ul>
<li><code>gmm</code>: 通用GMM估计</li>
<li><code>ivreg</code>: 工具变量回归</li>
<li><code>AER</code>: 应用计量包，包含GMM函数</li>
<li><code>lavaan</code>: 结构方程模型（GMM的特例）</li>
</ul></li>
<li><strong>Python库</strong>：
<ul>
<li><code>linearmodels</code>: 线性计量模型，包括IV、GMM</li>
<li><code>statsmodels</code>: 统计模型，包含GMM基础功能</li>
<li><code>econml</code>: 微软经济机器学习库</li>
</ul></li>
<li><strong>Stata命令</strong>：
<ul>
<li><code>ivregress</code>: 工具变量回归</li>
<li><code>gmm</code>: 广义矩估计</li>
<li><code>ivreg2</code>: 增强的IV估计</li>
</ul></li>
</ol>
</section>
<section id="在线课程" class="level3">
<h3 class="anchored" data-anchor-id="在线课程">在线课程</h3>
<ol type="1">
<li>Coursera: “Econometrics: Methods and Applications” (Erasmus University)</li>
<li>MIT OpenCourseWare: “Econometrics” (课程14.381)</li>
<li>中国大学MOOC: “高级计量经济学” (清华大学、厦门大学等)</li>
</ol>
</section>
</section>
<section id="思考与练习" class="level2">
<h2 class="anchored" data-anchor-id="思考与练习">思考与练习</h2>
<section id="理论推导" class="level3">
<h3 class="anchored" data-anchor-id="理论推导">理论推导</h3>
<ol type="1">
<li><strong>统一性证明</strong>：
<ul>
<li>证明当<span class="math inline">\(q=p\)</span>时，GMM估计量不依赖于权重矩阵<span class="math inline">\(\mathbf{W}_n\)</span>的选择</li>
<li>推导2SLS作为GMM特例的具体条件</li>
<li>证明在正确分布设定下，MLE的渐近方差达到Cramér-Rao下界</li>
</ul></li>
<li><strong>渐近性质</strong>：
<ul>
<li>推导GMM估计量的渐近方差公式</li>
<li>证明最优权重矩阵为<span class="math inline">\(\pmb{\Omega}^{-1}\)</span></li>
<li>推导Hansen’s J检验的渐近分布</li>
</ul></li>
</ol>
</section>
<section id="实证分析" class="level3">
<h3 class="anchored" data-anchor-id="实证分析">实证分析</h3>
<ol type="1">
<li><strong>数据练习</strong>：
<ul>
<li>使用Card (1995)数据，用GMM估计教育回报</li>
<li>比较OLS、2SLS、不同矩条件的GMM结果</li>
<li>进行弱工具变量诊断和过度识别检验</li>
</ul></li>
<li><strong>模型扩展</strong>：
<ul>
<li>构造动态面板数据的GMM估计</li>
<li>应用经验似然方法估计CCAPM参数</li>
<li>实现高维情况下的正则化GMM</li>
</ul></li>
</ol>
</section>
<section id="研究设计" class="level3">
<h3 class="anchored" data-anchor-id="研究设计">研究设计</h3>
<ol type="1">
<li><strong>矩条件构造</strong>：
<ul>
<li>为劳动供给弹性估计设计矩条件</li>
<li>为资产定价模型设计时间序列矩条件</li>
<li>为处理效应评估设计双重稳健矩条件</li>
</ul></li>
<li><strong>敏感性分析</strong>：
<ul>
<li>设计方案评估弱工具变量的影响</li>
<li>比较不同权重矩阵估计方法的表现</li>
<li>分析矩条件数量对估计结果的影响</li>
</ul></li>
</ol>
</section>
<section id="批判性思考" class="level3">
<h3 class="anchored" data-anchor-id="批判性思考">批判性思考</h3>
<ol type="1">
<li><strong>方法比较</strong>：
<ul>
<li>GMM与传统方法在哪些情况下差异显著？为什么？</li>
<li>有限样本下，何时应优先使用简单方法而非GMM？</li>
<li>如何权衡矩条件的数量与质量？</li>
</ul></li>
<li><strong>应用伦理</strong>：
<ul>
<li>如何避免”数据挖掘”式地选择矩条件？</li>
<li>在政策评估中，如何透明报告GMM的不确定性？</li>
<li>如何处理冲突的矩条件检验结果？</li>
</ul></li>
</ol>
<p><strong>学习目标</strong>：通过这些练习，您应能不仅理解GMM的数学原理，更能掌握其在实际研究中的恰当应用，培养出对计量方法选择的敏锐判断力。</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "已复制");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "已复制");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/15最大似然估计法.html" class="pagination-link" aria-label="15 最大似然估计理论">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">15 最大似然估计理论</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/17蒙特卡洛法与自助法.html" class="pagination-link" aria-label="17 蒙特卡洛法与自助法">
        <span class="nav-page-text"><span class="chapter-title">17 蒙特卡洛法与自助法</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>