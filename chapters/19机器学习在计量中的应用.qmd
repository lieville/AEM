---
title: "19 机器学习在计量中的应用"
author: "李世纪"
format: html
editor: visual
---

## 本章导读

在当今数据爆炸的时代，经济数据呈现出前所未有的复杂性：高维度、非线性、非结构化以及大规模特征。传统计量经济学方法在处理这些问题时，常常面临维数诅咒、模型设定偏误和过拟合等挑战。与此同时，机器学习方法在计算机科学、统计学等领域展现出强大的数据建模能力，特别是在预测和模式识别方面。然而，机器学习的预测导向与计量经济学的因果推断导向之间存在本质差异。本章旨在架起这两大领域的桥梁，系统介绍如何将机器学习方法有效、严谨地应用于计量经济学研究。

本章重点探讨机器学习技术如何服务于计量经济学的核心使命——因果识别与推断。我们将学习如何利用正则化方法处理高维控制变量，如何使用现代机器学习工具估计异质性处理效应，以及如何将无监督学习应用于经济数据的结构发现。特别地，我们将看到机器学习不仅不威胁计量经济学的因果推断传统，反而为克服传统方法的局限提供了新工具和新思路。

本章不要求读者具备深厚的机器学习背景，所有概念都将从计量经济学家的视角出发进行阐释。我们的目标是使读者能够理解这些方法的核心思想，掌握其适用条件，并能够在实际研究中审慎应用。

## 18.1 因果推断的新工具：机器学习下的处理效应估计

### 18.1.1 传统方法的局限与机器学习的优势

在因果推断中，我们通常关注处理效应（Treatment Effect）的估计。在Rubin的潜在结果框架下，个体$i$的处理效应定义为：

$$
\tau_i = Y_i(1) - Y_i(0)
$$

其中$Y_i(1)$和$Y_i(0)$分别表示个体$i$在接受处理和未接受处理时的潜在结果。传统方法如倾向得分匹配、双重差分法等在处理高维协变量、非线性关系以及异质性处理效应时面临挑战。

机器学习方法的优势在于： 1. **高维处理能力**：能有效处理协变量维度$p$大于样本量$n$的情况 2. **非线性建模**：能够自动捕捉变量间的复杂非线性关系和交互效应 3. **异质性识别**：可以估计个体层面的处理效应，而非仅关注平均处理效应 4. **正则化**：通过惩罚复杂模型防止过拟合，提高样本外预测能力

### 18.1.2 双重机器学习

Chernozhukov等（2018）提出的双重机器学习（Double/Debiased Machine Learning）为在因果推断中应用机器学习提供了理论框架。考虑以下部分线性模型：

$$
\begin{aligned}
Y &= D\theta_0 + g_0(X) + \zeta, \quad \mathbb{E}[\zeta|X,D] = 0 \\
D &= m_0(X) + V, \quad \mathbb{E}[V|X] = 0
\end{aligned}
$$

其中$D$是处理变量，$X$是高维协变量，$\theta_0$是我们关心的处理效应参数。双重机器学习估计量通过以下步骤获得：

1.  使用机器学习方法分别估计$Y$对$X$的回归函数$l_0(X) = \mathbb{E}[Y|X]$和$D$对$X$的回归函数$m_0(X) = \mathbb{E}[D|X]$
2.  构造残差： $$
    \tilde{Y} = Y - \hat{l}_0(X), \quad \tilde{D} = D - \hat{m}_0(X)
    $$
3.  通过以下回归估计处理效应： $$
    \hat{\theta}_0 = \left(\frac{1}{n}\sum_{i=1}^n \tilde{D}_i^2\right)^{-1}\frac{1}{n}\sum_{i=1}^n \tilde{D}_i\tilde{Y}_i
    $$

该估计量具有$\sqrt{n}$一致性，只要机器学习估计量以$o(n^{-1/4})$的速率收敛。

### 18.1.3 异质性处理效应的识别：因果森林

对于条件平均处理效应（CATE）： $$
\tau(x) = \mathbb{E}[Y(1) - Y(0)|X=x]
$$

Athey和Wager（2019）提出了因果森林（Causal Forest），这是随机森林在因果推断中的扩展。因果森林通过以下步骤估计CATE：

1.  将样本随机分成若干子集
2.  在每个子集上，通过以下目标函数进行分割： $$
    \Delta(C_1, C_2) = \frac{|C_1||C_2|}{|C|^2}\left(\hat{\tau}(C_1) - \hat{\tau}(C_2)\right)^2
    $$ 其中$\hat{\tau}(C)$是子集$C$内处理效应的估计
3.  对每个观测值$i$，收集包含它的所有叶子节点的处理效应估计，取平均作为最终估计

因果森林的估计量具有渐近正态性： $$
\sqrt{n}\left(\hat{\tau}(x) - \tau(x)\right) \xrightarrow{d} N(0, \sigma^2(x))
$$

### 18.1.4 实践案例：评估职业培训项目的异质性收益

考虑评估一项职业培训项目对参与者收入的影响。传统方法可能只提供平均处理效应，但实际影响可能因个体特征而异。使用因果森林，我们可以：

1.  收集数据：处理状态$D_i$（是否参与培训），结果变量$Y_i$（收入），协变量$X_i$（年龄、教育、工作经验等）
2.  使用因果森林估计条件平均处理效应$\hat{\tau}(x)$
3.  分析发现：培训项目对年轻、低教育水平的参与者效果显著，但对高教育水平参与者效果不显著

这种异质性分析为政策优化提供了重要依据。

## 18.2 高维控制与变量选择：从Lasso到正则化回归

### 18.2.1 高维数据下的"维数诅咒"与稀疏性假设

在高维数据中，当协变量数量$p$超过样本量$n$时，普通最小二乘法（OLS）不可行，因为设计矩阵不满秩。更一般地，当$p$与$n$可比拟时，OLS估计量的方差很大，预测性能差。

解决高维问题的关键假设是**稀疏性**：尽管有大量潜在协变量，但只有少数对结果有实质性影响。形式上，假设真实模型为： $$
Y = X\beta^* + \epsilon
$$ 其中$\beta^*$是$p$维向量，但只有$s \ll p$个非零元素。

### 18.2.2 核心方法：Lasso、岭回归与弹性网络

**Lasso（Least Absolute Shrinkage and Selection Operator）** Lasso通过$L_1$惩罚实现变量选择和系数收缩： $$
\hat{\beta}^{lasso} = \arg\min_{\beta} \left\{\frac{1}{2n}\|Y - X\beta\|_2^2 + \lambda\|\beta\|_1\right\}
$$ 其中$\lambda > 0$是调节参数，$\|\beta\|_1 = \sum_{j=1}^p |\beta_j|$。$L_1$惩罚的几何特性使得某些系数恰好为零，从而实现变量选择。

**岭回归（Ridge Regression）** 岭回归使用$L_2$惩罚： $$
\hat{\beta}^{ridge} = \arg\min_{\beta} \left\{\frac{1}{2n}\|Y - X\beta\|_2^2 + \lambda\|\beta\|_2^2\right\}
$$ 其中$\|\beta\|_2^2 = \sum_{j=1}^p \beta_j^2$。岭回归收缩系数但不将其设为零，适用于所有变量都有微小影响的情况。

**弹性网络（Elastic Net）** 弹性网络结合了$L_1$和$L_2$惩罚： $$
\hat{\beta}^{enet} = \arg\min_{\beta} \left\{\frac{1}{2n}\|Y - X\beta\|_2^2 + \lambda\left(\alpha\|\beta\|_1 + \frac{1}{2}(1-\alpha)\|\beta\|_2^2\right)\right\}
$$ 其中$\alpha \in [0,1]$控制两种惩罚的混合比例。弹性网络在处理高度相关变量时比Lasso更稳定。

### 18.2.3 后选择推断

在Lasso进行变量选择后，直接对所选变量进行OLS推断会产生偏误，因为选择过程引入了数据窥视（data snooping）。后选择推断方法提供有效的置信区间：

**去偏Lasso（Debiased Lasso）** 对于Lasso估计量$\hat{\beta}$，构造去偏估计： $$
\hat{b} = \hat{\beta} + \frac{1}{n}\hat{\Theta}X^\top(Y - X\hat{\beta})
$$ 其中$\hat{\Theta}$是精度矩阵$\Sigma^{-1}$的估计。在适当条件下，去偏估计量满足： $$
\sqrt{n}(\hat{b}_j - \beta_j^*) \xrightarrow{d} N(0, \sigma_j^2)
$$ 可用于构造置信区间。

### 18.2.4 应用：在收入决定模型中控制海量家庭特征

研究教育对收入的影响时，需要控制大量家庭背景变量。假设我们有$p=500$个潜在控制变量（包括家庭资产、父母教育、社区特征等），但样本只有$n=1000$。

1.  使用弹性网络选择相关控制变量
2.  得到稀疏模型，只包含约30个重要变量
3.  在控制这些变量后，估计教育回报率
4.  使用去偏Lasso计算教育回报率的置信区间

这种方法比主观选择控制变量更系统、更可靠。

## 18.3 结构识别与数据模式发现：异常检测与结构突变

### 18.3.1 无监督学习在计量经济中的角色

无监督学习不依赖标签数据，而是从数据本身发现结构。在计量经济学中，无监督学习主要用于： 1. 数据探索和模式发现 2. 异常值和离群点检测 3. 结构变化和断点识别 4. 降维和特征提取

### 18.3.2 检测经济与金融异常值：孤立森林

孤立森林（Isolation Forest）是一种高效的异常检测算法。其核心思想是：异常点稀少且与正常点差异大，因此更容易被"孤立"。

算法流程： 1. 随机选择一个特征和分割点 2. 递归地分割数据，直到每个点被孤立或达到深度限制 3. 异常点具有较短的平均路径长度

对于观测值$x$，异常分数定义为： $$
s(x,n) = 2^{-\frac{E(h(x))}{c(n)}}
$$ 其中$E(h(x))$是$x$在多次树中的平均路径长度，$c(n)$是平均路径长度的标准化因子。$s(x,n)$接近1表示很可能是异常值。

在经济金融中，孤立森林可用于： - 检测财务报表欺诈 - 识别金融市场异常交易 - 发现经济数据中的录入错误

### 18.3.3 识别经济关系的结构断点

考虑时间序列模型： $$
y_t = \begin{cases}
f_1(x_t, \theta_1) + \epsilon_t, & t \leq \tau \\
f_2(x_t, \theta_2) + \epsilon_t, & t > \tau
\end{cases}
$$

其中$\tau$是未知的结构断点。传统方法如Bai-Perron检验假设$f$是线性形式，机器学习方法可以处理非线性断点。

**基于机器学习的断点检测**： 1. 将时间序列划分为多个窗口 2. 在每个窗口内训练预测模型 3. 比较相邻窗口模型的预测差异 4. 当预测差异超过阈值时，标记为潜在断点

对于非线性模型，定义断点统计量： $$
Q(\tau) = \frac{1}{T}\sum_{t=1}^T \left(\hat{f}_1(x_t) - \hat{f}_2(x_t)\right)^2
$$ 其中$\hat{f}_1$和$\hat{f}_2$分别是断点前后训练的模型。

### 18.3.4 应用：金融危机预警与政策体制转换识别

**金融危机预警**： 1. 收集多种经济指标（股市波动率、信用利差、外汇储备等） 2. 使用孤立森林识别异常时期 3. 发现这些异常时期往往领先于金融危机

**货币政策体制转换**： 1. 使用断点检测方法分析中央银行利率政策 2. 识别从通胀目标制到非传统货币政策的转换点 3. 分析不同体制下货币政策传导机制的变化

## 18.4 面板数据的深化：机器学习与个体异质性建模

### 18.4.1 超越固定效应：在面板数据中引入非线性与交互效应

传统面板数据模型： $$
y_{it} = \alpha_i + x_{it}^\top\beta + \epsilon_{it}
$$ 假设个体效应$\alpha_i$是加性的，且与$x_{it}$的关系是线性的。

机器学习扩展允许更灵活的设定： $$
y_{it} = g(x_{it}, \alpha_i) + \epsilon_{it}
$$ 其中$g(\cdot)$可以是任意复杂函数，通过神经网络或树模型估计。

### 18.4.2 机器学习方法估计时变个体效应

考虑时变个体效应模型： $$
y_{it} = \alpha_{it} + x_{it}^\top\beta + \epsilon_{it}
$$

使用矩阵分解方法： $$
\min_{\alpha,\beta} \sum_{i=1}^N\sum_{t=1}^T (y_{it} - \alpha_{it} - x_{it}^\top\beta)^2 + \lambda R(\alpha)
$$ 其中$R(\alpha)$是惩罚项，鼓励$\alpha$具有低秩或平滑结构。

例如，假设$\alpha$可分解为： $$
\alpha_{it} = u_i^\top v_t
$$ 其中$u_i \in \mathbb{R}^k$，$v_t \in \mathbb{R}^k$，$k \ll \min(N,T)$。这实质上是面板数据的因子模型。

### 18.4.3 交互固定效应模型与机器学习的结合

Bai（2009）的交互固定效应模型： $$
y_{it} = x_{it}^\top\beta + \lambda_i^\top f_t + \epsilon_{it}
$$

机器学习方法可以估计更一般的形式： $$
y_{it} = h(x_{it}) + \lambda_i^\top f_t + \epsilon_{it}
$$ 其中$h(\cdot)$通过机器学习方法估计。

估计步骤： 1. 使用主成分分析估计因子结构：$\hat{f}_t$和$\hat{\lambda}_i$ 2. 构造残差：$\tilde{y}_{it} = y_{it} - \hat{\lambda}_i^\top \hat{f}_t$ 3. 在残差上使用机器学习估计：$\hat{h}(x) = \arg\min_h \sum_{i,t} (\tilde{y}_{it} - h(x_{it}))^2 + \lambda J(h)$

### 18.4.4 应用：企业生产率分析中的异质性技术溢出效应

研究研发投入对企业生产率的影响： - 传统方法：估计平均弹性 - 机器学习方法：允许异质性影响

模型设定： $$
\ln(Prod_{it}) = h(RD_{it}, Controls_{it}) + \alpha_i + \gamma_t + \epsilon_{it}
$$

其中$h(\cdot)$通过梯度提升树估计。研究发现： 1. 研发对生产率的促进作用呈非线性：边际效应递减 2. 异质性明显：对高科技企业影响更大 3. 存在互补性：研发与人力资本投资有协同效应

## 18.5 政策评估的强化：基于机器学习的合成控制与反事实构建

### 18.5.1 合成控制法的回顾及其机器学习扩展

传统合成控制法（Abadie等，2010）用于评估处理单元（如实施政策的地区）的处理效应。对于处理单元$i=0$（$t \geq T_0$后接受处理），寻找权重$w^* = (w_1, ..., w_J)$使得： $$
\min_{w} \|X_0 - X_c w\|_V \quad \text{s.t.} \quad w_j \geq 0, \sum_{j=1}^J w_j = 1
$$ 其中$X_0$是处理单元的处理前特征，$X_c$是控制单元的特征矩阵，$V$是权重矩阵。

合成控制法的机器学习扩展： 1. **广义合成控制**：放松凸组合约束，允许负权重和权重大于1 2. **矩阵补全方法**：将反事实预测视为矩阵补全问题 3. **正则化合成控制**：加入惩罚项防止过拟合

### 18.5.2 矩阵补全方法与反事实预测

将面板数据视为矩阵$Y \in \mathbb{R}^{N \times T}$，其中部分条目缺失（处理后的处理单元结果）。矩阵补全的目标是： $$
\min_{M} \sum_{(i,t)\in \Omega} (Y_{it} - M_{it})^2 + \lambda \|M\|_*
$$ 其中$\Omega$是观测到的条目集合，$\|M\|_*$是核范数（奇异值之和），鼓励低秩结构。

对于处理单元$i=0$在$t \geq T_0$的反事实预测： $$
\hat{Y}_{0t}(0) = \hat{M}_{0t}, \quad t \geq T_0
$$ 处理效应估计： $$
\hat{\tau}_{0t} = Y_{0t} - \hat{Y}_{0t}(0), \quad t \geq T_0
$$

### 18.5.3 广义合成控制与正则化合成控制

**广义合成控制**（Xu，2017）： $$
\hat{w}^{GSC} = \arg\min_{w} \left\{\sum_{t=1}^{T_0} (Y_{0t} - \sum_{j=1}^J w_j Y_{jt})^2 + \lambda\|w\|_2^2\right\}
$$ 放松了非负和求和为1的约束，但增加了$L_2$惩罚。

**正则化合成控制**（Arkhangelsky等，2021）： 考虑更一般的因子模型： $$
Y_{it}(0) = \alpha_i + \beta_t + \lambda_i^\top f_t + \epsilon_{it}
$$ 使用矩阵补全方法估计缺失的反事实。

### 18.5.4 应用：评估大型区域性经济政策（如特区设立）的净效应

评估某经济特区设立对区域经济增长的影响： - 处理单元：设立特区的城市 - 控制单元：其他类似城市 - 结果变量：人均GDP增长率

**传统合成控制法局限**： 1. 只能处理单一处理单元 2. 对处理前拟合要求高 3. 权重非负约束可能限制拟合效果

**机器学习改进方法**： 1. 使用矩阵补全方法，同时估计多个特区的效应 2. 允许处理前拟合不完美，但保证模型复杂度受控 3. 得到处理效应的动态路径和置信区间

研究发现：特区政策在短期（1-3年）内效应不明显，长期（5年以上）显著促进经济增长，但存在区域异质性。

## 本章总结

本章系统探讨了机器学习方法在计量经济学中的五大核心应用领域，展示了这些现代数据科学工具如何丰富和扩展传统计量经济学方法论。

在**因果推断**方面，我们学习了双重机器学习和因果森林等方法，它们使得在高维数据中估计处理效应和识别异质性成为可能。这些方法严格建立在计量经济学因果推断框架内，为处理复杂观测数据提供了新工具。

在**高维控制与变量选择**方面，正则化方法如Lasso、岭回归和弹性网络解决了"维数诅咒"问题，使得研究者能够系统地从大量潜在控制变量中选择相关变量，减少模型设定偏误。

在**结构识别与模式发现**方面，无监督学习方法如孤立森林为检测经济异常和识别结构变化提供了自动化工具，帮助经济学家从数据中发现新的经验规律。

在**面板数据分析**方面，机器学习方法允许更灵活地建模个体异质性和时间效应，特别是通过因子模型与机器学习的结合，能够捕捉复杂的个体-时间交互效应。

在**政策评估**方面，机器学习增强了合成控制法等反事实预测方法，通过矩阵补全和正则化技术，提高了政策效应估计的精度和稳健性。

需要特别强调的是，机器学习的引入不是要取代传统计量经济学，而是要弥补其在高维、非线性、复杂数据环境中的不足。成功的应用需要深刻理解计量经济学的因果推断逻辑，审慎选择机器学习工具，并正确解释结果。

未来，"计量机器学习"这一交叉领域将继续蓬勃发展，可能的方向包括： 1. 发展更适合经济数据特性的机器学习算法 2. 建立更完整的理论框架，理解机器学习方法的经济计量性质 3. 开发用户友好的软件包，降低方法应用门槛 4. 探索机器学习在结构计量模型中的应用

计量经济学与机器学习的融合，正推动着经验经济学研究向更严谨、更精细、更实用的方向发展。

## 本章练习题

1.  **概念辨析**：比较双重机器学习与传统工具变量法在解决内生性问题时的逻辑异同。双重机器学习如何处理不可观测的混杂变量？

2.  **方法操作**：考虑线性模型$Y = X\beta + \epsilon$，其中$X$为$n \times p$设计矩阵，$p > n$。推导Lasso估计量$\hat{\beta}$的闭式解（当$X^\top X = I$时），并解释$L_1$惩罚如何导致稀疏性。

3.  **案例分析**：设计一个研究方案，利用**因果森林**方法评估"提高最低工资"政策对不同规模、不同地区企业的就业效应差异。需详细说明：

    -   所需数据类型和来源
    -   核心变量定义和度量
    -   因果森林的具体设定和参数选择
    -   如何解释异质性处理效应结果
    -   可能的识别挑战和解决方案

4.  **模型比较**：在政策评估中，比较**传统合成控制法**、**广义合成控制法**和**矩阵补全方法**：

    -   各自的假设条件是什么？
    -   各适用于什么类型的数据和政策评估问题？
    -   如何从实证角度比较这些方法的优劣？

5.  **综合论述**："机器学习虽然预测能力强，但对计量经济学追求的因果推断构成了威胁。"请结合本章内容，对此观点进行评述。讨论：

    -   预测和因果推断的根本区别
    -   机器学习如何可能威胁因果推断（如过拟合、黑箱问题）
    -   如何正确使用机器学习辅助因果推断而非威胁它
    -   计量机器学习方法如何保持因果推断的严谨性